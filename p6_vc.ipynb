{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "from ultralytics import YOLO\n",
    "from retinaface import RetinaFace\n",
    "import mediapipe as mp\n",
    "from mediapipe.tasks import python\n",
    "from mediapipe.tasks.python import vision\n",
    "import numpy as np\n",
    "from dataclasses import dataclass\n",
    "from typing import Any, List\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelo    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class Emotions:\n",
    "    name : str\n",
    "    quantity : int\n",
    "\n",
    "@dataclass\n",
    "class Point:\n",
    "    x : float\n",
    "    y : float\n",
    "\n",
    "@dataclass\n",
    "class BoundingBox:\n",
    "    origin : Point\n",
    "    end: Point\n",
    "\n",
    "\n",
    "class Genre:\n",
    "    male = 'MALE'\n",
    "    female = 'FEMALE'\n",
    "\n",
    "    def __init__(self, genre : str):\n",
    "        self.genre = genre\n",
    "\n",
    "    @staticmethod\n",
    "    def female():\n",
    "        return Genre(Genre.female)\n",
    "    \n",
    "    @staticmethod\n",
    "    def male():\n",
    "        return Genre(Genre.male)\n",
    "    \n",
    "    def isMale(self):\n",
    "        return self.genre == Genre.male\n",
    "\n",
    "    def isFemale(self):\n",
    "        return self.genre == Genre.female\n",
    "\n",
    "@dataclass\n",
    "class Person:\n",
    "    age : str\n",
    "    genre : Genre\n",
    "    emotions : List[Emotions]\n",
    "    bounding_box : BoundingBox\n",
    "    image : np.ndarray\n",
    "\n",
    "@dataclass\n",
    "class FaceDetectorResult:\n",
    "    image : np.ndarray \n",
    "    bounding_box : BoundingBox\n",
    "\n",
    "@dataclass\n",
    "class FaceComparatorResult:\n",
    "    similarity : float"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AplicaciÃ³n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from abc import ABC, abstractmethod\n",
    "from typing import List\n",
    "\n",
    "class FaceDetector(ABC):\n",
    "    @abstractmethod\n",
    "    def detect(self, image : np.ndarray) -> List[FaceDetectorResult]:\n",
    "        pass\n",
    "\n",
    "class FaceQualifier(ABC):\n",
    "    @abstractmethod\n",
    "    def qualify(self, face_detector_result : FaceDetectorResult) -> Person:\n",
    "        pass\n",
    "\n",
    "class FaceComparator(ABC):\n",
    "    @abstractmethod\n",
    "    def qualify(self, first_face : FaceDetectorResult, second_face: FaceDetectorResult) -> FaceComparatorResult:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Infraestructura\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageUtils:\n",
    "    @staticmethod\n",
    "    def crop(image : np.array, bounding_box : BoundingBox) -> np.ndarray:\n",
    "        return image[bounding_box.origin.x:bounding_box.end.x, bounding_box.origin.y:bounding_box.end.y]\n",
    "    \n",
    "    @staticmethod\n",
    "    def overlay_icon(image: np.array, icon_path: str, color: tuple, icon_size : int, point : tuple) -> np.ndarray:\n",
    "        # Read the icon image\n",
    "        icon = cv2.imread(icon_path, cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "        # Resize the icon to the specified size\n",
    "        icon = cv2.resize(icon, (icon_size, icon_size))\n",
    "\n",
    "        # Ensure the icon fits within the image at the specified origin\n",
    "        #icon = ImageUtils.rescale_with_border(icon, image.shape[1], image.shape[0])\n",
    "\n",
    "        # Create a mask where the icon is not zero\n",
    "        mask = icon == 0\n",
    "\n",
    "        # Create a color layer the same size as the adjusted icon\n",
    "        color_layer = np.full((icon.shape[0], icon.shape[1], 3), color, dtype=np.uint8)\n",
    "\n",
    "        # Use the mask to combine the color layer and the region of interest\n",
    "        np.copyto(image[point[1]-icon.shape[0]//2:point[1]+icon.shape[0]//2, point[0]-icon.shape[1]//2:point[0]+icon.shape[1]//2], color_layer, where=mask[:,:,None])\n",
    "\n",
    "        return image\n",
    "# Example usage\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class ViolaJonesFaceDetector(FaceDetector):\n",
    "    cascPathface = os.path.dirname(\n",
    "        cv2.__file__) + \"/data/haarcascade_frontalface_alt2.xml\"\n",
    "\n",
    "\n",
    "    def detect(self, image : np.ndarray) -> List[FaceDetectorResult]:\n",
    "        faceCascade = cv2.CascadeClassifier(self.cascPathface)\n",
    "        gray = self._convert_image_to_gray(image)\n",
    "        faces = faceCascade.detectMultiScale(gray,\n",
    "                                         scaleFactor=1.1,\n",
    "                                         minNeighbors=5,\n",
    "                                         minSize=(60, 60),\n",
    "                                         flags=cv2.CASCADE_SCALE_IMAGE)\n",
    "        return self._convert_to_face_detector_result(image, faces)\n",
    "        \n",
    "    \n",
    "    def _convert_to_face_detector_result(self, image, faces) -> List[FaceDetectorResult]:\n",
    "        bounding_boxes = [BoundingBox(Point(x, y), Point(x+w, y+h)) for (x, y, w, h) in faces]\n",
    "        return [FaceDetectorResult(ImageUtils.crop(image, bounding_box), bounding_box) for bounding_box in bounding_boxes]\n",
    "    \n",
    "    def _convert_image_to_gray(self, image : np.ndarray) -> np.ndarray:\n",
    "        import cv2\n",
    "        return cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "class RetinafaceFaceDetector(FaceDetector):\n",
    "    def detect(self, image : np.ndarray) -> List[FaceDetectorResult]:\n",
    "        faces = RetinaFace.detect_faces(image);\n",
    "        return self._convert_to_face_detector_result(image, [faces[key]['facial_area'] for key in faces.keys()])\n",
    "    \n",
    "    def _convert_to_face_detector_result(self, image, faces) -> List[FaceDetectorResult]:\n",
    "        bounding_boxes = [BoundingBox(Point(x, y), Point(w, h)) for (x, y, w, h) in faces]\n",
    "        return [FaceDetectorResult(ImageUtils.crop(image, bounding_box), bounding_box) for bounding_box in bounding_boxes]\n",
    "\n",
    "class MediaPipeFaceDetector(FaceDetector):\n",
    "    def detect(self, image : np.ndarray) -> List[FaceDetectorResult]:\n",
    "        BaseOptions = mp.tasks.BaseOptions\n",
    "        FaceDetector = mp.tasks.vision.FaceDetector\n",
    "        FaceDetectorOptions = mp.tasks.vision.FaceDetectorOptions\n",
    "        VisionRunningMode = mp.tasks.vision.RunningMode\n",
    "\n",
    "        options = FaceDetectorOptions(\n",
    "            base_options=BaseOptions(model_asset_path='./blaze_face_short_range.tflite'),\n",
    "            running_mode=VisionRunningMode.IMAGE)\n",
    "\n",
    "        with FaceDetector.create_from_options(options) as detector:\n",
    "            mp_image = mp.Image(image_format=mp.ImageFormat.SRGB, data=image)\n",
    "            face_detector_result = detector.detect(mp_image)\n",
    "            return self._convert_to_face_detector_result(image, [(x.bounding_box.origin_x, x.bounding_box.origin_y, x.bounding_box.width, x.bounding_box.height) for x in face_detector_result.detections])\n",
    "        \n",
    "    def _convert_to_face_detector_result(self, image, faces) -> List[FaceDetectorResult]:\n",
    "        bounding_boxes = [BoundingBox(Point(x, y), Point(x + w, y + h)) for (x, y, w, h) in faces]\n",
    "        return [FaceDetectorResult(ImageUtils.crop(image, bounding_box), bounding_box) for bounding_box in bounding_boxes]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MockFaceQualifier(FaceQualifier):\n",
    "    def qualify(self, face_detector_result):\n",
    "        return Person(\n",
    "            age=43, \n",
    "            genre=Genre.male(), \n",
    "            emotions=[Emotions('happy', 0.8),\n",
    "                      Emotions('sad', 0.5),\n",
    "                      Emotions('angry', 0.3)\n",
    "                      ], \n",
    "            bounding_box=face_detector_result.bounding_box, \n",
    "            image=face_detector_result.image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FaceQualificationDisplay:\n",
    "    def show():\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as cv\n",
    "\n",
    "class OpenCVFaceQualificationDisplay(FaceQualificationDisplay):\n",
    "    def __init__(self, people : List[Person], frame : np.ndarray) -> None:\n",
    "        self.people = people\n",
    "        self.frame = frame\n",
    "    \n",
    "    def display_emotions_right_of_person(self, person: Person, padding_x: int, padding_y: int) -> None:\n",
    "        width = 200\n",
    "        border_width =2\n",
    "        rectangle_origin = (person.bounding_box.end.x + border_width, person.bounding_box.origin.y - border_width)\n",
    "        rectangle_end = (rectangle_origin[0] + width, person.bounding_box.end.y + border_width)\n",
    "        if rectangle_end[0] > self.frame.shape[1]:\n",
    "            rectangle_end = (self.frame.shape[1], rectangle_end[1])\n",
    "        if rectangle_end[1] > self.frame.shape[0]:\n",
    "            rectangle_end = (rectangle_end[0], self.frame.shape[0])\n",
    "        #blur the rectangle background\n",
    "        self.frame[rectangle_origin[1]:rectangle_end[1], rectangle_origin[0]:rectangle_end[0]] = cv.GaussianBlur(self.frame[rectangle_origin[1]:rectangle_end[1], rectangle_origin[0]:rectangle_end[0]], (75, 75), 0) / 1.5\n",
    "\n",
    "        font_weight=1\n",
    "        font_size=0.8\n",
    "        text = \"Emotions\"\n",
    "        text_size, _ = cv.getTextSize(text, cv.FONT_HERSHEY_DUPLEX, font_size, font_weight)\n",
    "        text_width, text_height = text_size\n",
    "        text_x = rectangle_origin[0] + (rectangle_end[0] - rectangle_origin[0]) // 2 - text_width // 2\n",
    "        text_y = rectangle_origin[1] + text_height + padding_y // 2\n",
    "        cv.putText(self.frame, text, (text_x, text_y), cv.FONT_HERSHEY_DUPLEX, font_size, (255, 255, 255), font_weight, lineType = cv2.LINE_AA)\n",
    "\n",
    "        gap = 40\n",
    "\n",
    "        for x in person.emotions:\n",
    "            #draw text of emotion\n",
    "            font_weight=1\n",
    "            font_size=0.5\n",
    "            text = x.name + \": \" + str(x.quantity)\n",
    "            text_size, _ = cv.getTextSize(text, cv.FONT_HERSHEY_DUPLEX, font_size, font_weight)\n",
    "            text_width, text_height = text_size\n",
    "            text_x = rectangle_origin[0] + (rectangle_end[0] - rectangle_origin[0]) // 2 - text_width // 2\n",
    "            text_y = (rectangle_origin[1] + text_height + padding_y // 2) + gap\n",
    "            cv.putText(self.frame, text, (text_x, text_y), cv.FONT_HERSHEY_DUPLEX, font_size, (255, 255, 255), font_weight, lineType = cv2.LINE_AA)\n",
    "            gap+=30\n",
    "\n",
    "\n",
    "    def display_age_on_top_of_person(self, person: Person, padding_x: int, padding_y: int) -> None:\n",
    "        gap = 26\n",
    "        font_thinkness = 2\n",
    "        icon_size = 38\n",
    "        triangle_size = 20\n",
    "\n",
    "        text = str(person.age)\n",
    "        text_size, _ = cv.getTextSize(text, cv.FONT_HERSHEY_DUPLEX, 1.5, font_thinkness)\n",
    "        text_width, text_height = text_size\n",
    "\n",
    "        rectangle_origin = ((person.bounding_box.origin.x + (person.bounding_box.end.x - person.bounding_box.origin.x) // 2 - (text_width + padding_x) // 2), person.bounding_box.origin.y - text_height - padding_y - 50)\n",
    "        rectangle_end = (rectangle_origin[0] + text_width + padding_x, rectangle_origin[1] + text_height + padding_y)\n",
    "\n",
    "        # Draw the rectangle with a pointer\n",
    "        cv.rectangle(self.frame, rectangle_origin, rectangle_end, (67, 193, 246), cv.FILLED)\n",
    "\n",
    "        # Center the text within the rectangle\n",
    "        text_x = rectangle_origin[0] + (rectangle_end[0] - rectangle_origin[0]) // 2 - text_width // 2\n",
    "        text_y = rectangle_origin[1] + text_height + padding_y // 2\n",
    "\n",
    "        # Draw the text\n",
    "        cv.putText(self.frame, text, (text_x - gap, text_y), cv.FONT_HERSHEY_DUPLEX, 1.5, (47, 123, 222), font_thinkness, lineType = cv2.LINE_AA)\n",
    "\n",
    "        triangle = np.array([[rectangle_origin[0] + (rectangle_end[0] - rectangle_origin[0]) // 2 - triangle_size + 5, rectangle_end[1]],\n",
    "                            [rectangle_origin[0] + (rectangle_end[0] - rectangle_origin[0]) // 2 + triangle_size - 5, rectangle_end[1]],\n",
    "                            [rectangle_origin[0] + (rectangle_end[0] - rectangle_origin[0]) // 2, rectangle_end[1] + triangle_size] ], np.int32)\n",
    "        \n",
    "        cv.drawContours(self.frame, [triangle], 0, (67, 193, 246), cv.FILLED)\n",
    "\n",
    "        male_icon = cv.imread(\"./assets/male.png\" if person.genre.isMale() else \"./assets/female.png\")  # Correct the path to your male icon image\n",
    "        if male_icon is not None:\n",
    "            male_icon = cv.resize(male_icon, (icon_size, icon_size))\n",
    "            rectangle_center = (rectangle_origin[0] + (rectangle_end[0] - rectangle_origin[0]) // 2, rectangle_origin[1] + icon_size // 2 + padding_y//2)\n",
    "            self.overlay_icon(male_icon, (rectangle_center[0] + gap, rectangle_center[1]))\n",
    "        else:\n",
    "            print(\"Male icon not found or there's an error in reading the image.\")\n",
    "    \n",
    "    def overlay_icon(self, icon, center):\n",
    "        \"\"\"Overlay an icon image at the specified top left corner position.\"\"\"\n",
    "        h, w, _ = icon.shape\n",
    "        x, y = center\n",
    "        # Check if the coordinates are within the frame bounds\n",
    "        #draw only if the icon fits inside the frame\n",
    "        if x-w//2 >= 0 and y-h//2 >= 0 and x+w//2 < self.frame.shape[1] and y+h//2 < self.frame.shape[0]:\n",
    "            self.frame[y-h//2:y+h//2, x-w//2:x+w//2] = icon\n",
    "    \n",
    "    def display_box_around_person(self, person : Person) -> None:\n",
    "        cv.rectangle(self.frame, (person.bounding_box.origin.x, \n",
    "                                  person.bounding_box.origin.y), \n",
    "                                  (person.bounding_box.end.x, \n",
    "                                   person.bounding_box.end.y), \n",
    "                                   (67, 193, 246), 2)\n",
    "    \n",
    "    def show(self):\n",
    "        for person in self.people:\n",
    "            self.display_box_around_person(person)\n",
    "            self.display_age_on_top_of_person(person, 130, 38)\n",
    "            self.display_emotions_right_of_person(person, 130, 38)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class MockFaceComparator(FaceComparator):\n",
    "    def qualify(self, first_face, second_face):\n",
    "        return FaceComparatorResult(0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DeepfaceFaceComparator(FaceComparator):\n",
    "    def qualify(self, first_face, second_face):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CV2 INTERFACE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FaceQualificationDisplay(ABC):\n",
    "    @abstractmethod\n",
    "    def show(self) -> None:\n",
    "        pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AuthenticationScreen(ABC):\n",
    "    @abstractmethod\n",
    "    def display(self) -> None:\n",
    "        pass\n",
    "\n",
    "class IconAuthenticationScreen(AuthenticationScreen):\n",
    "    def __init__(self, frame : np.ndarray, icon_path : str, color : tuple, text : str, bg_color : str, alpha : float = 0.15) -> None:\n",
    "        self.frame = frame\n",
    "        self.icon_path = icon_path\n",
    "        self.color = color\n",
    "        self.text = text\n",
    "        self.bg_color = self.color if(bg_color == None) else bg_color\n",
    "        self.alpha  = alpha\n",
    "\n",
    "    def overlay_green_screen(self):\n",
    "        # Create a green screen of the same size as the frame\n",
    "        screen = np.full(self.frame.shape, self.bg_color, dtype=np.uint8)\n",
    "        alpha = self.alpha\n",
    "        self.frame[:,:] = cv2.addWeighted(self.frame, 1 - alpha, screen, alpha, 0)\n",
    "\n",
    "    def display(self) -> None:\n",
    "        self.overlay_green_screen()\n",
    "        ImageUtils.overlay_icon(image=self.frame, \n",
    "                                icon_path=self.icon_path, \n",
    "                                color=self.color, \n",
    "                                icon_size=200, \n",
    "                                point=(self.frame.shape[1] // 2, self.frame.shape[0] // 2))\n",
    "        #draw text that says Press any key to unlock\n",
    "        font_weight=2\n",
    "        font_size=1.2\n",
    "        text = self.text\n",
    "        text_size, _ = cv.getTextSize(text, cv.FONT_HERSHEY_DUPLEX, font_size, font_weight)\n",
    "        text_width, text_height = text_size\n",
    "        text_x = self.frame.shape[1] // 2 - text_width // 2\n",
    "        text_y = self.frame.shape[0] // 2 + text_height + 150\n",
    "        cv.putText(self.frame, text, (text_x, text_y), cv.FONT_HERSHEY_DUPLEX, font_size, self.color, font_weight, lineType = cv2.LINE_AA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "class LockAuthenticationScreen(IconAuthenticationScreen):\n",
    "    def __init__(self, frame: np.ndarray) -> None:\n",
    "        super().__init__(frame, \"./assets/lock.png\", (255, 255, 255), \"PRESS A KEY TO START FACE RECOGNITION\", bg_color=(0, 0, 0), alpha=0.4)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AccessGrantedAuthenticationScreen(IconAuthenticationScreen):\n",
    "    def __init__(self, frame: np.ndarray) -> None:\n",
    "        super().__init__(frame, \"./assets/success.png\", (0, 255, 0), \"ACCESS GRANTED\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AccessDeniedAuthenticationScreen(IconAuthenticationScreen):\n",
    "    def __init__(self, frame: np.ndarray) -> None:\n",
    "        super().__init__(frame, \"./assets/danger.png\", (0, 0, 255), \"ACCESS DENIED\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1701800865.229217       1 gl_context.cc:344] GL version: 2.1 (2.1 ATI-4.12.7), renderer: AMD Radeon Pro 5300M OpenGL Engine\n",
      "I0000 00:00:1701800865.293798       1 gl_context.cc:344] GL version: 2.1 (2.1 ATI-4.12.7), renderer: AMD Radeon Pro 5300M OpenGL Engine\n",
      "I0000 00:00:1701800865.361692       1 gl_context.cc:344] GL version: 2.1 (2.1 ATI-4.12.7), renderer: AMD Radeon Pro 5300M OpenGL Engine\n",
      "I0000 00:00:1701800865.427507       1 gl_context.cc:344] GL version: 2.1 (2.1 ATI-4.12.7), renderer: AMD Radeon Pro 5300M OpenGL Engine\n",
      "I0000 00:00:1701800865.495268       1 gl_context.cc:344] GL version: 2.1 (2.1 ATI-4.12.7), renderer: AMD Radeon Pro 5300M OpenGL Engine\n",
      "I0000 00:00:1701800865.561868       1 gl_context.cc:344] GL version: 2.1 (2.1 ATI-4.12.7), renderer: AMD Radeon Pro 5300M OpenGL Engine\n",
      "I0000 00:00:1701800865.626593       1 gl_context.cc:344] GL version: 2.1 (2.1 ATI-4.12.7), renderer: AMD Radeon Pro 5300M OpenGL Engine\n",
      "I0000 00:00:1701800865.693838       1 gl_context.cc:344] GL version: 2.1 (2.1 ATI-4.12.7), renderer: AMD Radeon Pro 5300M OpenGL Engine\n",
      "I0000 00:00:1701800865.760495       1 gl_context.cc:344] GL version: 2.1 (2.1 ATI-4.12.7), renderer: AMD Radeon Pro 5300M OpenGL Engine\n",
      "I0000 00:00:1701800865.828279       1 gl_context.cc:344] GL version: 2.1 (2.1 ATI-4.12.7), renderer: AMD Radeon Pro 5300M OpenGL Engine\n",
      "I0000 00:00:1701800865.893963       1 gl_context.cc:344] GL version: 2.1 (2.1 ATI-4.12.7), renderer: AMD Radeon Pro 5300M OpenGL Engine\n",
      "I0000 00:00:1701800865.960789       1 gl_context.cc:344] GL version: 2.1 (2.1 ATI-4.12.7), renderer: AMD Radeon Pro 5300M OpenGL Engine\n",
      "I0000 00:00:1701800866.027924       1 gl_context.cc:344] GL version: 2.1 (2.1 ATI-4.12.7), renderer: AMD Radeon Pro 5300M OpenGL Engine\n",
      "I0000 00:00:1701800866.093265       1 gl_context.cc:344] GL version: 2.1 (2.1 ATI-4.12.7), renderer: AMD Radeon Pro 5300M OpenGL Engine\n",
      "I0000 00:00:1701800866.161161       1 gl_context.cc:344] GL version: 2.1 (2.1 ATI-4.12.7), renderer: AMD Radeon Pro 5300M OpenGL Engine\n",
      "I0000 00:00:1701800866.227066       1 gl_context.cc:344] GL version: 2.1 (2.1 ATI-4.12.7), renderer: AMD Radeon Pro 5300M OpenGL Engine\n",
      "I0000 00:00:1701800866.292763       1 gl_context.cc:344] GL version: 2.1 (2.1 ATI-4.12.7), renderer: AMD Radeon Pro 5300M OpenGL Engine\n",
      "I0000 00:00:1701800866.360076       1 gl_context.cc:344] GL version: 2.1 (2.1 ATI-4.12.7), renderer: AMD Radeon Pro 5300M OpenGL Engine\n",
      "I0000 00:00:1701800866.427550       1 gl_context.cc:344] GL version: 2.1 (2.1 ATI-4.12.7), renderer: AMD Radeon Pro 5300M OpenGL Engine\n",
      "I0000 00:00:1701800866.493387       1 gl_context.cc:344] GL version: 2.1 (2.1 ATI-4.12.7), renderer: AMD Radeon Pro 5300M OpenGL Engine\n",
      "I0000 00:00:1701800866.561369       1 gl_context.cc:344] GL version: 2.1 (2.1 ATI-4.12.7), renderer: AMD Radeon Pro 5300M OpenGL Engine\n",
      "I0000 00:00:1701800866.627195       1 gl_context.cc:344] GL version: 2.1 (2.1 ATI-4.12.7), renderer: AMD Radeon Pro 5300M OpenGL Engine\n",
      "I0000 00:00:1701800866.694562       1 gl_context.cc:344] GL version: 2.1 (2.1 ATI-4.12.7), renderer: AMD Radeon Pro 5300M OpenGL Engine\n",
      "I0000 00:00:1701800866.758904       1 gl_context.cc:344] GL version: 2.1 (2.1 ATI-4.12.7), renderer: AMD Radeon Pro 5300M OpenGL Engine\n",
      "I0000 00:00:1701800866.826543       1 gl_context.cc:344] GL version: 2.1 (2.1 ATI-4.12.7), renderer: AMD Radeon Pro 5300M OpenGL Engine\n",
      "I0000 00:00:1701800866.893929       1 gl_context.cc:344] GL version: 2.1 (2.1 ATI-4.12.7), renderer: AMD Radeon Pro 5300M OpenGL Engine\n",
      "I0000 00:00:1701800866.960938       1 gl_context.cc:344] GL version: 2.1 (2.1 ATI-4.12.7), renderer: AMD Radeon Pro 5300M OpenGL Engine\n",
      "I0000 00:00:1701800867.027516       1 gl_context.cc:344] GL version: 2.1 (2.1 ATI-4.12.7), renderer: AMD Radeon Pro 5300M OpenGL Engine\n",
      "I0000 00:00:1701800867.094590       1 gl_context.cc:344] GL version: 2.1 (2.1 ATI-4.12.7), renderer: AMD Radeon Pro 5300M OpenGL Engine\n",
      "I0000 00:00:1701800867.160647       1 gl_context.cc:344] GL version: 2.1 (2.1 ATI-4.12.7), renderer: AMD Radeon Pro 5300M OpenGL Engine\n",
      "I0000 00:00:1701800867.225936       1 gl_context.cc:344] GL version: 2.1 (2.1 ATI-4.12.7), renderer: AMD Radeon Pro 5300M OpenGL Engine\n",
      "I0000 00:00:1701800867.292930       1 gl_context.cc:344] GL version: 2.1 (2.1 ATI-4.12.7), renderer: AMD Radeon Pro 5300M OpenGL Engine\n",
      "I0000 00:00:1701800867.359165       1 gl_context.cc:344] GL version: 2.1 (2.1 ATI-4.12.7), renderer: AMD Radeon Pro 5300M OpenGL Engine\n",
      "I0000 00:00:1701800867.427100       1 gl_context.cc:344] GL version: 2.1 (2.1 ATI-4.12.7), renderer: AMD Radeon Pro 5300M OpenGL Engine\n",
      "I0000 00:00:1701800867.493372       1 gl_context.cc:344] GL version: 2.1 (2.1 ATI-4.12.7), renderer: AMD Radeon Pro 5300M OpenGL Engine\n",
      "I0000 00:00:1701800867.560855       1 gl_context.cc:344] GL version: 2.1 (2.1 ATI-4.12.7), renderer: AMD Radeon Pro 5300M OpenGL Engine\n",
      "I0000 00:00:1701800867.626806       1 gl_context.cc:344] GL version: 2.1 (2.1 ATI-4.12.7), renderer: AMD Radeon Pro 5300M OpenGL Engine\n",
      "I0000 00:00:1701800867.694254       1 gl_context.cc:344] GL version: 2.1 (2.1 ATI-4.12.7), renderer: AMD Radeon Pro 5300M OpenGL Engine\n",
      "I0000 00:00:1701800867.759816       1 gl_context.cc:344] GL version: 2.1 (2.1 ATI-4.12.7), renderer: AMD Radeon Pro 5300M OpenGL Engine\n",
      "I0000 00:00:1701800867.826469       1 gl_context.cc:344] GL version: 2.1 (2.1 ATI-4.12.7), renderer: AMD Radeon Pro 5300M OpenGL Engine\n",
      "I0000 00:00:1701800867.893132       1 gl_context.cc:344] GL version: 2.1 (2.1 ATI-4.12.7), renderer: AMD Radeon Pro 5300M OpenGL Engine\n",
      "I0000 00:00:1701800867.959724       1 gl_context.cc:344] GL version: 2.1 (2.1 ATI-4.12.7), renderer: AMD Radeon Pro 5300M OpenGL Engine\n",
      "I0000 00:00:1701800868.025510       1 gl_context.cc:344] GL version: 2.1 (2.1 ATI-4.12.7), renderer: AMD Radeon Pro 5300M OpenGL Engine\n",
      "I0000 00:00:1701800868.092690       1 gl_context.cc:344] GL version: 2.1 (2.1 ATI-4.12.7), renderer: AMD Radeon Pro 5300M OpenGL Engine\n",
      "I0000 00:00:1701800868.158632       1 gl_context.cc:344] GL version: 2.1 (2.1 ATI-4.12.7), renderer: AMD Radeon Pro 5300M OpenGL Engine\n",
      "I0000 00:00:1701800868.226063       1 gl_context.cc:344] GL version: 2.1 (2.1 ATI-4.12.7), renderer: AMD Radeon Pro 5300M OpenGL Engine\n",
      "I0000 00:00:1701800868.293155       1 gl_context.cc:344] GL version: 2.1 (2.1 ATI-4.12.7), renderer: AMD Radeon Pro 5300M OpenGL Engine\n",
      "I0000 00:00:1701800868.358944       1 gl_context.cc:344] GL version: 2.1 (2.1 ATI-4.12.7), renderer: AMD Radeon Pro 5300M OpenGL Engine\n",
      "I0000 00:00:1701800868.427269       1 gl_context.cc:344] GL version: 2.1 (2.1 ATI-4.12.7), renderer: AMD Radeon Pro 5300M OpenGL Engine\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/josepenaseco/Desktop/dev/vc/p6/p6_vc.ipynb Celda 20\u001b[0m line \u001b[0;36m8\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/josepenaseco/Desktop/dev/vc/p6/p6_vc.ipynb#X33sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m ret, frame \u001b[39m=\u001b[39m video\u001b[39m.\u001b[39mread()\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/josepenaseco/Desktop/dev/vc/p6/p6_vc.ipynb#X33sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m face_detector \u001b[39m=\u001b[39m MediaPipeFaceDetector()\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/josepenaseco/Desktop/dev/vc/p6/p6_vc.ipynb#X33sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m faces \u001b[39m=\u001b[39m face_detector\u001b[39m.\u001b[39;49mdetect(frame)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/josepenaseco/Desktop/dev/vc/p6/p6_vc.ipynb#X33sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m qualifier \u001b[39m=\u001b[39m MockFaceQualifier()\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/josepenaseco/Desktop/dev/vc/p6/p6_vc.ipynb#X33sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m qualifications \u001b[39m=\u001b[39m [qualifier\u001b[39m.\u001b[39mqualify(face) \u001b[39mfor\u001b[39;00m face \u001b[39min\u001b[39;00m faces]\n",
      "\u001b[1;32m/Users/josepenaseco/Desktop/dev/vc/p6/p6_vc.ipynb Celda 20\u001b[0m line \u001b[0;36m4\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/josepenaseco/Desktop/dev/vc/p6/p6_vc.ipynb#X33sZmlsZQ%3D%3D?line=44'>45</a>\u001b[0m \u001b[39mwith\u001b[39;00m FaceDetector\u001b[39m.\u001b[39mcreate_from_options(options) \u001b[39mas\u001b[39;00m detector:\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/josepenaseco/Desktop/dev/vc/p6/p6_vc.ipynb#X33sZmlsZQ%3D%3D?line=45'>46</a>\u001b[0m     mp_image \u001b[39m=\u001b[39m mp\u001b[39m.\u001b[39mImage(image_format\u001b[39m=\u001b[39mmp\u001b[39m.\u001b[39mImageFormat\u001b[39m.\u001b[39mSRGB, data\u001b[39m=\u001b[39mimage)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/josepenaseco/Desktop/dev/vc/p6/p6_vc.ipynb#X33sZmlsZQ%3D%3D?line=46'>47</a>\u001b[0m     face_detector_result \u001b[39m=\u001b[39m detector\u001b[39m.\u001b[39;49mdetect(mp_image)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/josepenaseco/Desktop/dev/vc/p6/p6_vc.ipynb#X33sZmlsZQ%3D%3D?line=47'>48</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_convert_to_face_detector_result(image, [(x\u001b[39m.\u001b[39mbounding_box\u001b[39m.\u001b[39morigin_x, x\u001b[39m.\u001b[39mbounding_box\u001b[39m.\u001b[39morigin_y, x\u001b[39m.\u001b[39mbounding_box\u001b[39m.\u001b[39mwidth, x\u001b[39m.\u001b[39mbounding_box\u001b[39m.\u001b[39mheight) \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m face_detector_result\u001b[39m.\u001b[39mdetections])\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.4/lib/python3.11/site-packages/mediapipe/tasks/python/vision/face_detector.py:217\u001b[0m, in \u001b[0;36mFaceDetector.detect\u001b[0;34m(self, image, image_processing_options)\u001b[0m\n\u001b[1;32m    195\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Performs face detection on the provided MediaPipe Image.\u001b[39;00m\n\u001b[1;32m    196\u001b[0m \n\u001b[1;32m    197\u001b[0m \u001b[39mOnly use this method when the FaceDetector is created with the image\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    212\u001b[0m \u001b[39m  RuntimeError: If face detection failed to run.\u001b[39;00m\n\u001b[1;32m    213\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    214\u001b[0m normalized_rect \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconvert_to_normalized_rect(\n\u001b[1;32m    215\u001b[0m     image_processing_options, image, roi_allowed\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m\n\u001b[1;32m    216\u001b[0m )\n\u001b[0;32m--> 217\u001b[0m output_packets \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_process_image_data({\n\u001b[1;32m    218\u001b[0m     _IMAGE_IN_STREAM_NAME: packet_creator\u001b[39m.\u001b[39;49mcreate_image(image),\n\u001b[1;32m    219\u001b[0m     _NORM_RECT_STREAM_NAME: packet_creator\u001b[39m.\u001b[39;49mcreate_proto(\n\u001b[1;32m    220\u001b[0m         normalized_rect\u001b[39m.\u001b[39;49mto_pb2()\n\u001b[1;32m    221\u001b[0m     ),\n\u001b[1;32m    222\u001b[0m })\n\u001b[1;32m    223\u001b[0m \u001b[39mif\u001b[39;00m output_packets[_DETECTIONS_OUT_STREAM_NAME]\u001b[39m.\u001b[39mis_empty():\n\u001b[1;32m    224\u001b[0m   \u001b[39mreturn\u001b[39;00m FaceDetectorResult([])\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.4/lib/python3.11/site-packages/mediapipe/tasks/python/vision/core/base_vision_task_api.py:95\u001b[0m, in \u001b[0;36mBaseVisionTaskApi._process_image_data\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m     90\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_running_mode \u001b[39m!=\u001b[39m _RunningMode\u001b[39m.\u001b[39mIMAGE:\n\u001b[1;32m     91\u001b[0m   \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m     92\u001b[0m       \u001b[39m'\u001b[39m\u001b[39mTask is not initialized with the image mode. Current running mode:\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m     93\u001b[0m       \u001b[39m+\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_running_mode\u001b[39m.\u001b[39mname\n\u001b[1;32m     94\u001b[0m   )\n\u001b[0;32m---> 95\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_runner\u001b[39m.\u001b[39;49mprocess(inputs)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import cv2 as cv\n",
    "\n",
    "video = cv.VideoCapture(0)\n",
    "\n",
    "while True:\n",
    "    ret, frame = video.read()\n",
    "    face_detector = MediaPipeFaceDetector()\n",
    "    faces = face_detector.detect(frame)\n",
    "    qualifier = MockFaceQualifier()\n",
    "    qualifications = [qualifier.qualify(face) for face in faces]\n",
    "    display = OpenCVFaceQualificationDisplay(qualifications, frame)\n",
    "    display.show()\n",
    "\n",
    "    cv.imshow('Video', frame)\n",
    "\n",
    "    if cv.waitKey(1) & 0xFF == ord('q'):\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FACE AUTHENTICATOR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Callable\n",
    "\n",
    "@dataclass\n",
    "class Transition:\n",
    "    next_state : str\n",
    "    actions: List[Callable[[], bool]]\n",
    "\n",
    "@dataclass\n",
    "class State:\n",
    "    name : str\n",
    "    screen : AuthenticationScreen\n",
    "    transition_to : List[Transition]\n",
    "\n",
    "class AuthenticationStateMachine(ABC):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1701800807.418211       1 gl_context.cc:344] GL version: 2.1 (2.1 ATI-4.12.7), renderer: AMD Radeon Pro 5300M OpenGL Engine\n",
      "I0000 00:00:1701800807.481936       1 gl_context.cc:344] GL version: 2.1 (2.1 ATI-4.12.7), renderer: AMD Radeon Pro 5300M OpenGL Engine\n",
      "I0000 00:00:1701800807.548931       1 gl_context.cc:344] GL version: 2.1 (2.1 ATI-4.12.7), renderer: AMD Radeon Pro 5300M OpenGL Engine\n",
      "I0000 00:00:1701800807.614829       1 gl_context.cc:344] GL version: 2.1 (2.1 ATI-4.12.7), renderer: AMD Radeon Pro 5300M OpenGL Engine\n",
      "I0000 00:00:1701800807.681906       1 gl_context.cc:344] GL version: 2.1 (2.1 ATI-4.12.7), renderer: AMD Radeon Pro 5300M OpenGL Engine\n",
      "I0000 00:00:1701800807.748591       1 gl_context.cc:344] GL version: 2.1 (2.1 ATI-4.12.7), renderer: AMD Radeon Pro 5300M OpenGL Engine\n",
      "I0000 00:00:1701800807.815155       1 gl_context.cc:344] GL version: 2.1 (2.1 ATI-4.12.7), renderer: AMD Radeon Pro 5300M OpenGL Engine\n",
      "I0000 00:00:1701800807.882089       1 gl_context.cc:344] GL version: 2.1 (2.1 ATI-4.12.7), renderer: AMD Radeon Pro 5300M OpenGL Engine\n",
      "I0000 00:00:1701800807.948938       1 gl_context.cc:344] GL version: 2.1 (2.1 ATI-4.12.7), renderer: AMD Radeon Pro 5300M OpenGL Engine\n",
      "I0000 00:00:1701800808.014627       1 gl_context.cc:344] GL version: 2.1 (2.1 ATI-4.12.7), renderer: AMD Radeon Pro 5300M OpenGL Engine\n",
      "I0000 00:00:1701800808.081652       1 gl_context.cc:344] GL version: 2.1 (2.1 ATI-4.12.7), renderer: AMD Radeon Pro 5300M OpenGL Engine\n",
      "I0000 00:00:1701800808.148214       1 gl_context.cc:344] GL version: 2.1 (2.1 ATI-4.12.7), renderer: AMD Radeon Pro 5300M OpenGL Engine\n",
      "I0000 00:00:1701800808.215144       1 gl_context.cc:344] GL version: 2.1 (2.1 ATI-4.12.7), renderer: AMD Radeon Pro 5300M OpenGL Engine\n",
      "I0000 00:00:1701800808.281661       1 gl_context.cc:344] GL version: 2.1 (2.1 ATI-4.12.7), renderer: AMD Radeon Pro 5300M OpenGL Engine\n",
      "I0000 00:00:1701800808.348212       1 gl_context.cc:344] GL version: 2.1 (2.1 ATI-4.12.7), renderer: AMD Radeon Pro 5300M OpenGL Engine\n",
      "I0000 00:00:1701800808.414865       1 gl_context.cc:344] GL version: 2.1 (2.1 ATI-4.12.7), renderer: AMD Radeon Pro 5300M OpenGL Engine\n",
      "I0000 00:00:1701800808.481712       1 gl_context.cc:344] GL version: 2.1 (2.1 ATI-4.12.7), renderer: AMD Radeon Pro 5300M OpenGL Engine\n",
      "I0000 00:00:1701800808.547874       1 gl_context.cc:344] GL version: 2.1 (2.1 ATI-4.12.7), renderer: AMD Radeon Pro 5300M OpenGL Engine\n",
      "I0000 00:00:1701800808.614673       1 gl_context.cc:344] GL version: 2.1 (2.1 ATI-4.12.7), renderer: AMD Radeon Pro 5300M OpenGL Engine\n",
      "I0000 00:00:1701800808.681222       1 gl_context.cc:344] GL version: 2.1 (2.1 ATI-4.12.7), renderer: AMD Radeon Pro 5300M OpenGL Engine\n",
      "I0000 00:00:1701800808.748405       1 gl_context.cc:344] GL version: 2.1 (2.1 ATI-4.12.7), renderer: AMD Radeon Pro 5300M OpenGL Engine\n",
      "I0000 00:00:1701800808.814776       1 gl_context.cc:344] GL version: 2.1 (2.1 ATI-4.12.7), renderer: AMD Radeon Pro 5300M OpenGL Engine\n",
      "I0000 00:00:1701800808.881365       1 gl_context.cc:344] GL version: 2.1 (2.1 ATI-4.12.7), renderer: AMD Radeon Pro 5300M OpenGL Engine\n",
      "I0000 00:00:1701800808.947898       1 gl_context.cc:344] GL version: 2.1 (2.1 ATI-4.12.7), renderer: AMD Radeon Pro 5300M OpenGL Engine\n",
      "I0000 00:00:1701800809.014588       1 gl_context.cc:344] GL version: 2.1 (2.1 ATI-4.12.7), renderer: AMD Radeon Pro 5300M OpenGL Engine\n",
      "I0000 00:00:1701800809.081175       1 gl_context.cc:344] GL version: 2.1 (2.1 ATI-4.12.7), renderer: AMD Radeon Pro 5300M OpenGL Engine\n",
      "I0000 00:00:1701800809.147739       1 gl_context.cc:344] GL version: 2.1 (2.1 ATI-4.12.7), renderer: AMD Radeon Pro 5300M OpenGL Engine\n",
      "I0000 00:00:1701800809.214385       1 gl_context.cc:344] GL version: 2.1 (2.1 ATI-4.12.7), renderer: AMD Radeon Pro 5300M OpenGL Engine\n",
      "I0000 00:00:1701800809.281201       1 gl_context.cc:344] GL version: 2.1 (2.1 ATI-4.12.7), renderer: AMD Radeon Pro 5300M OpenGL Engine\n",
      "I0000 00:00:1701800809.348033       1 gl_context.cc:344] GL version: 2.1 (2.1 ATI-4.12.7), renderer: AMD Radeon Pro 5300M OpenGL Engine\n",
      "I0000 00:00:1701800809.414581       1 gl_context.cc:344] GL version: 2.1 (2.1 ATI-4.12.7), renderer: AMD Radeon Pro 5300M OpenGL Engine\n",
      "I0000 00:00:1701800809.481077       1 gl_context.cc:344] GL version: 2.1 (2.1 ATI-4.12.7), renderer: AMD Radeon Pro 5300M OpenGL Engine\n",
      "I0000 00:00:1701800809.547696       1 gl_context.cc:344] GL version: 2.1 (2.1 ATI-4.12.7), renderer: AMD Radeon Pro 5300M OpenGL Engine\n",
      "I0000 00:00:1701800809.614315       1 gl_context.cc:344] GL version: 2.1 (2.1 ATI-4.12.7), renderer: AMD Radeon Pro 5300M OpenGL Engine\n",
      "I0000 00:00:1701800809.681676       1 gl_context.cc:344] GL version: 2.1 (2.1 ATI-4.12.7), renderer: AMD Radeon Pro 5300M OpenGL Engine\n",
      "I0000 00:00:1701800809.747725       1 gl_context.cc:344] GL version: 2.1 (2.1 ATI-4.12.7), renderer: AMD Radeon Pro 5300M OpenGL Engine\n",
      "I0000 00:00:1701800809.814674       1 gl_context.cc:344] GL version: 2.1 (2.1 ATI-4.12.7), renderer: AMD Radeon Pro 5300M OpenGL Engine\n",
      "I0000 00:00:1701800809.880742       1 gl_context.cc:344] GL version: 2.1 (2.1 ATI-4.12.7), renderer: AMD Radeon Pro 5300M OpenGL Engine\n",
      "I0000 00:00:1701800809.947518       1 gl_context.cc:344] GL version: 2.1 (2.1 ATI-4.12.7), renderer: AMD Radeon Pro 5300M OpenGL Engine\n",
      "I0000 00:00:1701800810.014990       1 gl_context.cc:344] GL version: 2.1 (2.1 ATI-4.12.7), renderer: AMD Radeon Pro 5300M OpenGL Engine\n",
      "I0000 00:00:1701800810.080992       1 gl_context.cc:344] GL version: 2.1 (2.1 ATI-4.12.7), renderer: AMD Radeon Pro 5300M OpenGL Engine\n",
      "I0000 00:00:1701800810.147467       1 gl_context.cc:344] GL version: 2.1 (2.1 ATI-4.12.7), renderer: AMD Radeon Pro 5300M OpenGL Engine\n",
      "I0000 00:00:1701800810.214083       1 gl_context.cc:344] GL version: 2.1 (2.1 ATI-4.12.7), renderer: AMD Radeon Pro 5300M OpenGL Engine\n",
      "I0000 00:00:1701800810.281678       1 gl_context.cc:344] GL version: 2.1 (2.1 ATI-4.12.7), renderer: AMD Radeon Pro 5300M OpenGL Engine\n",
      "I0000 00:00:1701800810.348530       1 gl_context.cc:344] GL version: 2.1 (2.1 ATI-4.12.7), renderer: AMD Radeon Pro 5300M OpenGL Engine\n",
      "I0000 00:00:1701800810.415021       1 gl_context.cc:344] GL version: 2.1 (2.1 ATI-4.12.7), renderer: AMD Radeon Pro 5300M OpenGL Engine\n",
      "I0000 00:00:1701800810.481166       1 gl_context.cc:344] GL version: 2.1 (2.1 ATI-4.12.7), renderer: AMD Radeon Pro 5300M OpenGL Engine\n",
      "I0000 00:00:1701800810.548130       1 gl_context.cc:344] GL version: 2.1 (2.1 ATI-4.12.7), renderer: AMD Radeon Pro 5300M OpenGL Engine\n",
      "I0000 00:00:1701800810.614156       1 gl_context.cc:344] GL version: 2.1 (2.1 ATI-4.12.7), renderer: AMD Radeon Pro 5300M OpenGL Engine\n",
      "I0000 00:00:1701800810.681059       1 gl_context.cc:344] GL version: 2.1 (2.1 ATI-4.12.7), renderer: AMD Radeon Pro 5300M OpenGL Engine\n",
      "I0000 00:00:1701800810.747406       1 gl_context.cc:344] GL version: 2.1 (2.1 ATI-4.12.7), renderer: AMD Radeon Pro 5300M OpenGL Engine\n",
      "I0000 00:00:1701800810.814187       1 gl_context.cc:344] GL version: 2.1 (2.1 ATI-4.12.7), renderer: AMD Radeon Pro 5300M OpenGL Engine\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/josepenaseco/Desktop/dev/vc/p6/p6_vc.ipynb Celda 22\u001b[0m line \u001b[0;36m6\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/josepenaseco/Desktop/dev/vc/p6/p6_vc.ipynb#X26sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m video \u001b[39m=\u001b[39m cv\u001b[39m.\u001b[39mVideoCapture(\u001b[39m0\u001b[39m)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/josepenaseco/Desktop/dev/vc/p6/p6_vc.ipynb#X26sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/josepenaseco/Desktop/dev/vc/p6/p6_vc.ipynb#X26sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m     ret, frame \u001b[39m=\u001b[39m video\u001b[39m.\u001b[39;49mread()\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/josepenaseco/Desktop/dev/vc/p6/p6_vc.ipynb#X26sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m     face_detector \u001b[39m=\u001b[39m MediaPipeFaceDetector()\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/josepenaseco/Desktop/dev/vc/p6/p6_vc.ipynb#X26sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m     faces \u001b[39m=\u001b[39m face_detector\u001b[39m.\u001b[39mdetect(frame)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import cv2 as cv\n",
    "\n",
    "video = cv.VideoCapture(0)\n",
    "\n",
    "while True:\n",
    "    ret, frame = video.read()\n",
    "    face_detector = MediaPipeFaceDetector()\n",
    "    faces = face_detector.detect(frame)\n",
    "    qualifier = MockFaceQualifier()\n",
    "    qualifications = [qualifier.qualify(face) for face in faces]\n",
    "    display = OpenCVFaceQualificationDisplay(qualifications, frame)\n",
    "    display.show()\n",
    "\n",
    "    cv.imshow('Video', frame)\n",
    "\n",
    "    if cv.waitKey(1) & 0xFF == ord('q'):\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
