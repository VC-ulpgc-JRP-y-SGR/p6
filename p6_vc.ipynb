{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "from retinaface import RetinaFace\n",
    "import mediapipe as mp\n",
    "from mediapipe.tasks import python\n",
    "from mediapipe.tasks.python import vision\n",
    "import numpy as np\n",
    "from dataclasses import dataclass\n",
    "from typing import Any, List\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelo    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class Emotions:\n",
    "    name : str\n",
    "    quantity : int\n",
    "\n",
    "@dataclass\n",
    "class Point:\n",
    "    x : float\n",
    "    y : float\n",
    "\n",
    "@dataclass\n",
    "class BoundingBox:\n",
    "    origin : Point\n",
    "    end: Point\n",
    "\n",
    "\n",
    "class Genre:\n",
    "    male = 'Man'\n",
    "    female = 'Woman'\n",
    "\n",
    "    def __init__(self, genre : str):\n",
    "        self.genre = genre\n",
    "\n",
    "    @staticmethod\n",
    "    def female():\n",
    "        return Genre(Genre.female)\n",
    "    \n",
    "    @staticmethod\n",
    "    def male():\n",
    "        return Genre(Genre.male)\n",
    "    \n",
    "    def isMale(self):\n",
    "        return self.genre == Genre.male\n",
    "\n",
    "    def isFemale(self):\n",
    "        return self.genre == Genre.female\n",
    "\n",
    "@dataclass\n",
    "class Person:\n",
    "    age : str\n",
    "    genre : Genre\n",
    "    emotions : List[Emotions]\n",
    "    bounding_box : BoundingBox\n",
    "    image : np.ndarray\n",
    "\n",
    "@dataclass\n",
    "class FaceDetectorResult:\n",
    "    image : np.ndarray \n",
    "    bounding_box : BoundingBox\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aplicación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from abc import ABC, abstractmethod\n",
    "from typing import List\n",
    "\n",
    "class FaceDetector(ABC):\n",
    "    @abstractmethod\n",
    "    def detect(self, image : np.ndarray) -> List[FaceDetectorResult]:\n",
    "        pass\n",
    "\n",
    "class FaceQualifier(ABC):\n",
    "    @abstractmethod\n",
    "    def qualify(self, face_detector_result : FaceDetectorResult) -> Person:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Infraestructura\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageUtils:\n",
    "    @staticmethod\n",
    "    def crop(image : np.array, bounding_box : BoundingBox) -> np.ndarray:\n",
    "        return image[bounding_box.origin.x:bounding_box.end.x, bounding_box.origin.y:bounding_box.end.y]\n",
    "    \n",
    "    @staticmethod\n",
    "    def overlay_icon(image: np.array, icon_path: str, color: tuple, icon_size : int, point : tuple) -> np.ndarray:\n",
    "        icon = cv2.imread(icon_path, cv2.IMREAD_GRAYSCALE)\n",
    "        icon = cv2.resize(icon, (icon_size, icon_size))\n",
    "        mask = icon == 0\n",
    "        color_layer = np.full((icon.shape[0], icon.shape[1], 3), color, dtype=np.uint8)\n",
    "        np.copyto(image[point[1]-icon.shape[0]//2:point[1]+icon.shape[0]//2, point[0]-icon.shape[1]//2:point[0]+icon.shape[1]//2], color_layer, where=mask[:,:,None])\n",
    "        return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class ViolaJonesFaceDetector(FaceDetector):\n",
    "    cascPathface = os.path.dirname(\n",
    "        cv2.__file__) + \"/data/haarcascade_frontalface_alt2.xml\"\n",
    "\n",
    "    def detect(self, image : np.ndarray) -> List[FaceDetectorResult]:\n",
    "        faceCascade = cv2.CascadeClassifier(self.cascPathface)\n",
    "        gray = self._convert_image_to_gray(image)\n",
    "        faces = faceCascade.detectMultiScale(gray,\n",
    "                                         scaleFactor=1.1,\n",
    "                                         minNeighbors=5,\n",
    "                                         minSize=(60, 60),\n",
    "                                         flags=cv2.CASCADE_SCALE_IMAGE)\n",
    "        return self._convert_to_face_detector_result(image, faces)\n",
    "        \n",
    "    \n",
    "    def _convert_to_face_detector_result(self, image, faces) -> List[FaceDetectorResult]:\n",
    "        bounding_boxes = [BoundingBox(Point(x, y), Point(x+w, y+h)) for (x, y, w, h) in faces]\n",
    "        return [FaceDetectorResult(ImageUtils.crop(image, bounding_box), bounding_box) for bounding_box in bounding_boxes]\n",
    "    \n",
    "    def _convert_image_to_gray(self, image : np.ndarray) -> np.ndarray:\n",
    "        import cv2\n",
    "        return cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "class RetinafaceFaceDetector(FaceDetector):\n",
    "    def detect(self, image : np.ndarray) -> List[FaceDetectorResult]:\n",
    "        faces = RetinaFace.detect_faces(image);\n",
    "        return self._convert_to_face_detector_result(image, [faces[key]['facial_area'] for key in faces.keys()])\n",
    "    \n",
    "    def _convert_to_face_detector_result(self, image, faces) -> List[FaceDetectorResult]:\n",
    "        bounding_boxes = [BoundingBox(Point(x, y), Point(w, h)) for (x, y, w, h) in faces]\n",
    "        return [FaceDetectorResult(ImageUtils.crop(image, bounding_box), bounding_box) for bounding_box in bounding_boxes]\n",
    "\n",
    "class MediaPipeFaceDetector(FaceDetector):\n",
    "    def detect(self, image : np.ndarray) -> List[FaceDetectorResult]:\n",
    "        BaseOptions = mp.tasks.BaseOptions\n",
    "        FaceDetector = mp.tasks.vision.FaceDetector\n",
    "        FaceDetectorOptions = mp.tasks.vision.FaceDetectorOptions\n",
    "        VisionRunningMode = mp.tasks.vision.RunningMode\n",
    "\n",
    "        options = FaceDetectorOptions(\n",
    "            base_options=BaseOptions(model_asset_path='./blaze_face_short_range.tflite'),\n",
    "            running_mode=VisionRunningMode.IMAGE)\n",
    "\n",
    "        with FaceDetector.create_from_options(options) as detector:\n",
    "            mp_image = mp.Image(image_format=mp.ImageFormat.SRGB, data=image)\n",
    "            face_detector_result = detector.detect(mp_image)\n",
    "            return self._convert_to_face_detector_result(image, [(x.bounding_box.origin_x, x.bounding_box.origin_y, x.bounding_box.width, x.bounding_box.height) for x in face_detector_result.detections])\n",
    "        \n",
    "    def _convert_to_face_detector_result(self, image, faces) -> List[FaceDetectorResult]:\n",
    "        bounding_boxes = [BoundingBox(Point(x, y), Point(x + w, y + h)) for (x, y, w, h) in faces]\n",
    "        return [FaceDetectorResult(ImageUtils.crop(image, bounding_box), bounding_box) for bounding_box in bounding_boxes]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MockFaceQualifier(FaceQualifier):\n",
    "    def qualify(self, face_detector_result):\n",
    "        return Person(\n",
    "            age=43, \n",
    "            genre=Genre.male(), \n",
    "            emotions=[Emotions('happy', 0.8),\n",
    "                      Emotions('sad', 0.5),\n",
    "                      Emotions('angry', 0.3)\n",
    "                      ], \n",
    "            bounding_box=face_detector_result.bounding_box, \n",
    "            image=face_detector_result.image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from deepface import DeepFace\n",
    "\n",
    "class DeepfaceFaceQualifier(FaceQualifier):\n",
    "    def qualify(self, face_detector_result: FaceDetectorResult) -> Person:\n",
    "        face_image = face_detector_result.image\n",
    "        deepface_result = DeepFace.analyze(img_path = face_image, actions = ['age', 'gender', 'emotion'], enforce_detection=False)[0]\n",
    "        \n",
    "        age = str(deepface_result[\"age\"])\n",
    "        gender = Genre(max(deepface_result[\"gender\"], key = deepface_result[\"gender\"].get))\n",
    "        emotion_predictions = deepface_result[\"emotion\"]\n",
    "        emotions = [Emotions(name=emotion, quantity=round(probability, 3)) for emotion, probability in emotion_predictions.items()]\n",
    "        sorted_emotions = sorted(emotions, key=lambda x: x.quantity, reverse=True)\n",
    "\n",
    "        person = Person(\n",
    "            age = age,\n",
    "            genre = gender,\n",
    "            emotions = sorted_emotions[0:3],\n",
    "            bounding_box = face_detector_result.bounding_box,\n",
    "            image = face_image\n",
    "        )\n",
    "        \n",
    "        return person"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FaceQualificationDisplay:\n",
    "    def show():\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as cv\n",
    "\n",
    "class OpenCVFaceQualificationDisplay(FaceQualificationDisplay):\n",
    "    def __init__(self, people : List[Person], frame : np.ndarray) -> None:\n",
    "        self.people = people\n",
    "        self.frame = frame\n",
    "    \n",
    "    def display_emotions_right_of_person(self, person: Person, padding_x: int, padding_y: int) -> None:\n",
    "        width = 200\n",
    "        border_width =2\n",
    "        rectangle_origin = (person.bounding_box.end.x + border_width, person.bounding_box.origin.y - border_width)\n",
    "        rectangle_end = (rectangle_origin[0] + width, person.bounding_box.end.y + border_width)\n",
    "        if rectangle_end[0] > self.frame.shape[1]:\n",
    "            rectangle_end = (self.frame.shape[1], rectangle_end[1])\n",
    "        if rectangle_end[1] > self.frame.shape[0]:\n",
    "            rectangle_end = (rectangle_end[0], self.frame.shape[0])\n",
    "        #blur the rectangle background\n",
    "        self.frame[rectangle_origin[1]:rectangle_end[1], rectangle_origin[0]:rectangle_end[0]] = cv.GaussianBlur(self.frame[rectangle_origin[1]:rectangle_end[1], rectangle_origin[0]:rectangle_end[0]], (75, 75), 0) / 1.5\n",
    "\n",
    "        font_weight=1\n",
    "        font_size=0.8\n",
    "        text = \"Emotions\"\n",
    "        text_size, _ = cv.getTextSize(text, cv.FONT_HERSHEY_DUPLEX, font_size, font_weight)\n",
    "        text_width, text_height = text_size\n",
    "        text_x = rectangle_origin[0] + (rectangle_end[0] - rectangle_origin[0]) // 2 - text_width // 2\n",
    "        text_y = rectangle_origin[1] + text_height + padding_y // 2\n",
    "        cv.putText(self.frame, text, (text_x, text_y), cv.FONT_HERSHEY_DUPLEX, font_size, (255, 255, 255), font_weight, lineType = cv2.LINE_AA)\n",
    "\n",
    "        gap = 40\n",
    "\n",
    "        for x in person.emotions:\n",
    "            #draw text of emotion\n",
    "            font_weight=1\n",
    "            font_size=0.5\n",
    "            text = x.name + \": \" + str(x.quantity)\n",
    "            text_size, _ = cv.getTextSize(text, cv.FONT_HERSHEY_DUPLEX, font_size, font_weight)\n",
    "            text_width, text_height = text_size\n",
    "            text_x = rectangle_origin[0] + (rectangle_end[0] - rectangle_origin[0]) // 2 - text_width // 2\n",
    "            text_y = (rectangle_origin[1] + text_height + padding_y // 2) + gap\n",
    "            cv.putText(self.frame, text, (text_x, text_y), cv.FONT_HERSHEY_DUPLEX, font_size, (255, 255, 255), font_weight, lineType = cv2.LINE_AA)\n",
    "            gap+=30\n",
    "\n",
    "\n",
    "    def display_age_on_top_of_person(self, person: Person, padding_x: int, padding_y: int) -> None:\n",
    "        gap = 26\n",
    "        font_thinkness = 2\n",
    "        icon_size = 38\n",
    "        triangle_size = 20\n",
    "\n",
    "        text = str(person.age)\n",
    "        text_size, _ = cv.getTextSize(text, cv.FONT_HERSHEY_DUPLEX, 1.5, font_thinkness)\n",
    "        text_width, text_height = text_size\n",
    "\n",
    "        rectangle_origin = ((person.bounding_box.origin.x + (person.bounding_box.end.x - person.bounding_box.origin.x) // 2 - (text_width + padding_x) // 2), person.bounding_box.origin.y - text_height - padding_y - 50)\n",
    "        rectangle_end = (rectangle_origin[0] + text_width + padding_x, rectangle_origin[1] + text_height + padding_y)\n",
    "\n",
    "        # Draw the rectangle with a pointer\n",
    "        cv.rectangle(self.frame, rectangle_origin, rectangle_end, (67, 193, 246), cv.FILLED)\n",
    "\n",
    "        # Center the text within the rectangle\n",
    "        text_x = rectangle_origin[0] + (rectangle_end[0] - rectangle_origin[0]) // 2 - text_width // 2\n",
    "        text_y = rectangle_origin[1] + text_height + padding_y // 2\n",
    "\n",
    "        # Draw the text\n",
    "        cv.putText(self.frame, text, (text_x - gap, text_y), cv.FONT_HERSHEY_DUPLEX, 1.5, (47, 123, 222), font_thinkness, lineType = cv2.LINE_AA)\n",
    "\n",
    "        triangle = np.array([[rectangle_origin[0] + (rectangle_end[0] - rectangle_origin[0]) // 2 - triangle_size + 5, rectangle_end[1]],\n",
    "                            [rectangle_origin[0] + (rectangle_end[0] - rectangle_origin[0]) // 2 + triangle_size - 5, rectangle_end[1]],\n",
    "                            [rectangle_origin[0] + (rectangle_end[0] - rectangle_origin[0]) // 2, rectangle_end[1] + triangle_size] ], np.int32)\n",
    "        \n",
    "        cv.drawContours(self.frame, [triangle], 0, (67, 193, 246), cv.FILLED)\n",
    "\n",
    "        male_icon = cv.imread(\"./assets/male.png\" if person.genre.isMale() else \"./assets/female.png\")  # Correct the path to your male icon image\n",
    "        if male_icon is not None:\n",
    "            male_icon = cv.resize(male_icon, (icon_size, icon_size))\n",
    "            rectangle_center = (rectangle_origin[0] + (rectangle_end[0] - rectangle_origin[0]) // 2, rectangle_origin[1] + icon_size // 2 + padding_y//2)\n",
    "            self.overlay_icon(male_icon, (rectangle_center[0] + gap, rectangle_center[1]))\n",
    "        else:\n",
    "            print(\"Male icon not found or there's an error in reading the image.\")\n",
    "    \n",
    "    def overlay_icon(self, icon, center):\n",
    "        \"\"\"Overlay an icon image at the specified top left corner position.\"\"\"\n",
    "        h, w, _ = icon.shape\n",
    "        x, y = center\n",
    "        # Check if the coordinates are within the frame bounds\n",
    "        #draw only if the icon fits inside the frame\n",
    "        if x-w//2 >= 0 and y-h//2 >= 0 and x+w//2 < self.frame.shape[1] and y+h//2 < self.frame.shape[0]:\n",
    "            self.frame[y-h//2:y+h//2, x-w//2:x+w//2] = icon\n",
    "    \n",
    "    def display_box_around_person(self, person : Person) -> None:\n",
    "        cv.rectangle(self.frame, (person.bounding_box.origin.x, \n",
    "                                  person.bounding_box.origin.y), \n",
    "                                  (person.bounding_box.end.x, \n",
    "                                   person.bounding_box.end.y), \n",
    "                                   (67, 193, 246), 2)\n",
    "    \n",
    "    def show(self):\n",
    "        for person in self.people:\n",
    "            self.display_box_around_person(person)\n",
    "            self.display_age_on_top_of_person(person, 130, 38)\n",
    "            self.display_emotions_right_of_person(person, 130, 38)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CV2 INTERFACE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FaceQualificationDisplay(ABC):\n",
    "    @abstractmethod\n",
    "    def show(self) -> None:\n",
    "        pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1701874259.560282       1 gl_context.cc:344] GL version: 2.1 (2.1 ATI-4.12.7), renderer: AMD Radeon Pro 5300M OpenGL Engine\n",
      "Action: emotion: 100%|██████████| 3/3 [00:00<00:00,  3.40it/s]\n",
      "I0000 00:00:1701874260.578449       1 gl_context.cc:344] GL version: 2.1 (2.1 ATI-4.12.7), renderer: AMD Radeon Pro 5300M OpenGL Engine\n",
      "Action: emotion: 100%|██████████| 3/3 [00:00<00:00,  6.76it/s]\n",
      "I0000 00:00:1701874261.111774       1 gl_context.cc:344] GL version: 2.1 (2.1 ATI-4.12.7), renderer: AMD Radeon Pro 5300M OpenGL Engine\n",
      "Action: emotion: 100%|██████████| 3/3 [00:00<00:00,  6.76it/s]\n",
      "I0000 00:00:1701874261.609264       1 gl_context.cc:344] GL version: 2.1 (2.1 ATI-4.12.7), renderer: AMD Radeon Pro 5300M OpenGL Engine\n",
      "Action: emotion: 100%|██████████| 3/3 [00:00<00:00,  6.76it/s]\n",
      "I0000 00:00:1701874262.109939       1 gl_context.cc:344] GL version: 2.1 (2.1 ATI-4.12.7), renderer: AMD Radeon Pro 5300M OpenGL Engine\n",
      "Action: emotion: 100%|██████████| 3/3 [00:00<00:00,  6.84it/s]\n",
      "I0000 00:00:1701874262.612268       1 gl_context.cc:344] GL version: 2.1 (2.1 ATI-4.12.7), renderer: AMD Radeon Pro 5300M OpenGL Engine\n",
      "Action: emotion: 100%|██████████| 3/3 [00:00<00:00,  6.72it/s]\n",
      "I0000 00:00:1701874263.143656       1 gl_context.cc:344] GL version: 2.1 (2.1 ATI-4.12.7), renderer: AMD Radeon Pro 5300M OpenGL Engine\n",
      "Action: emotion: 100%|██████████| 3/3 [00:00<00:00,  6.83it/s]\n",
      "I0000 00:00:1701874263.643549       1 gl_context.cc:344] GL version: 2.1 (2.1 ATI-4.12.7), renderer: AMD Radeon Pro 5300M OpenGL Engine\n",
      "Action: emotion: 100%|██████████| 3/3 [00:00<00:00,  6.76it/s]\n",
      "I0000 00:00:1701874264.141828       1 gl_context.cc:344] GL version: 2.1 (2.1 ATI-4.12.7), renderer: AMD Radeon Pro 5300M OpenGL Engine\n",
      "Action: emotion: 100%|██████████| 3/3 [00:00<00:00,  6.66it/s]\n",
      "I0000 00:00:1701874264.641853       1 gl_context.cc:344] GL version: 2.1 (2.1 ATI-4.12.7), renderer: AMD Radeon Pro 5300M OpenGL Engine\n",
      "Action: emotion: 100%|██████████| 3/3 [00:00<00:00,  6.80it/s]\n",
      "I0000 00:00:1701874265.143002       1 gl_context.cc:344] GL version: 2.1 (2.1 ATI-4.12.7), renderer: AMD Radeon Pro 5300M OpenGL Engine\n",
      "Action: emotion: 100%|██████████| 3/3 [00:00<00:00,  6.29it/s]\n",
      "I0000 00:00:1701874265.674529       1 gl_context.cc:344] GL version: 2.1 (2.1 ATI-4.12.7), renderer: AMD Radeon Pro 5300M OpenGL Engine\n",
      "Action: emotion: 100%|██████████| 3/3 [00:00<00:00,  6.49it/s]\n",
      "I0000 00:00:1701874266.209093       1 gl_context.cc:344] GL version: 2.1 (2.1 ATI-4.12.7), renderer: AMD Radeon Pro 5300M OpenGL Engine\n",
      "Action: emotion: 100%|██████████| 3/3 [00:00<00:00,  6.70it/s]\n",
      "I0000 00:00:1701874266.710423       1 gl_context.cc:344] GL version: 2.1 (2.1 ATI-4.12.7), renderer: AMD Radeon Pro 5300M OpenGL Engine\n",
      "Action: emotion: 100%|██████████| 3/3 [00:00<00:00,  7.00it/s]\n",
      "I0000 00:00:1701874267.208400       1 gl_context.cc:344] GL version: 2.1 (2.1 ATI-4.12.7), renderer: AMD Radeon Pro 5300M OpenGL Engine\n",
      "Action: emotion: 100%|██████████| 3/3 [00:00<00:00,  7.03it/s]\n",
      "I0000 00:00:1701874267.710885       1 gl_context.cc:344] GL version: 2.1 (2.1 ATI-4.12.7), renderer: AMD Radeon Pro 5300M OpenGL Engine\n",
      "Action: emotion: 100%|██████████| 3/3 [00:00<00:00,  7.03it/s]\n",
      "I0000 00:00:1701874268.209693       1 gl_context.cc:344] GL version: 2.1 (2.1 ATI-4.12.7), renderer: AMD Radeon Pro 5300M OpenGL Engine\n",
      "Action: emotion: 100%|██████████| 3/3 [00:00<00:00,  6.97it/s]\n",
      "I0000 00:00:1701874268.709628       1 gl_context.cc:344] GL version: 2.1 (2.1 ATI-4.12.7), renderer: AMD Radeon Pro 5300M OpenGL Engine\n",
      "Action: emotion: 100%|██████████| 3/3 [00:00<00:00,  6.98it/s]\n",
      "I0000 00:00:1701874269.206768       1 gl_context.cc:344] GL version: 2.1 (2.1 ATI-4.12.7), renderer: AMD Radeon Pro 5300M OpenGL Engine\n",
      "Action: emotion: 100%|██████████| 3/3 [00:00<00:00,  6.91it/s]\n",
      "I0000 00:00:1701874269.708686       1 gl_context.cc:344] GL version: 2.1 (2.1 ATI-4.12.7), renderer: AMD Radeon Pro 5300M OpenGL Engine\n",
      "Action: emotion: 100%|██████████| 3/3 [00:00<00:00,  7.08it/s]\n",
      "I0000 00:00:1701874270.208864       1 gl_context.cc:344] GL version: 2.1 (2.1 ATI-4.12.7), renderer: AMD Radeon Pro 5300M OpenGL Engine\n",
      "Action: emotion: 100%|██████████| 3/3 [00:00<00:00,  7.03it/s]\n",
      "I0000 00:00:1701874270.708081       1 gl_context.cc:344] GL version: 2.1 (2.1 ATI-4.12.7), renderer: AMD Radeon Pro 5300M OpenGL Engine\n",
      "Action: emotion: 100%|██████████| 3/3 [00:00<00:00,  7.06it/s]\n",
      "I0000 00:00:1701874271.208282       1 gl_context.cc:344] GL version: 2.1 (2.1 ATI-4.12.7), renderer: AMD Radeon Pro 5300M OpenGL Engine\n",
      "Action: emotion: 100%|██████████| 3/3 [00:00<00:00,  6.92it/s]\n",
      "I0000 00:00:1701874271.708443       1 gl_context.cc:344] GL version: 2.1 (2.1 ATI-4.12.7), renderer: AMD Radeon Pro 5300M OpenGL Engine\n",
      "Action: emotion: 100%|██████████| 3/3 [00:00<00:00,  7.03it/s]\n",
      "I0000 00:00:1701874272.206883       1 gl_context.cc:344] GL version: 2.1 (2.1 ATI-4.12.7), renderer: AMD Radeon Pro 5300M OpenGL Engine\n",
      "Action: emotion: 100%|██████████| 3/3 [00:00<00:00,  6.85it/s]\n",
      "I0000 00:00:1701874272.706631       1 gl_context.cc:344] GL version: 2.1 (2.1 ATI-4.12.7), renderer: AMD Radeon Pro 5300M OpenGL Engine\n",
      "Action: emotion: 100%|██████████| 3/3 [00:00<00:00,  6.93it/s]\n",
      "I0000 00:00:1701874273.206416       1 gl_context.cc:344] GL version: 2.1 (2.1 ATI-4.12.7), renderer: AMD Radeon Pro 5300M OpenGL Engine\n",
      "Action: emotion: 100%|██████████| 3/3 [00:00<00:00,  6.85it/s]\n",
      "I0000 00:00:1701874273.707097       1 gl_context.cc:344] GL version: 2.1 (2.1 ATI-4.12.7), renderer: AMD Radeon Pro 5300M OpenGL Engine\n",
      "Action: emotion: 100%|██████████| 3/3 [00:00<00:00,  6.97it/s]\n",
      "I0000 00:00:1701874274.206748       1 gl_context.cc:344] GL version: 2.1 (2.1 ATI-4.12.7), renderer: AMD Radeon Pro 5300M OpenGL Engine\n",
      "Action: emotion: 100%|██████████| 3/3 [00:00<00:00,  6.97it/s]\n",
      "I0000 00:00:1701874274.705625       1 gl_context.cc:344] GL version: 2.1 (2.1 ATI-4.12.7), renderer: AMD Radeon Pro 5300M OpenGL Engine\n",
      "Action: emotion: 100%|██████████| 3/3 [00:00<00:00,  7.01it/s]\n",
      "I0000 00:00:1701874275.206818       1 gl_context.cc:344] GL version: 2.1 (2.1 ATI-4.12.7), renderer: AMD Radeon Pro 5300M OpenGL Engine\n",
      "Action: emotion: 100%|██████████| 3/3 [00:00<00:00,  6.95it/s]\n",
      "I0000 00:00:1701874275.706722       1 gl_context.cc:344] GL version: 2.1 (2.1 ATI-4.12.7), renderer: AMD Radeon Pro 5300M OpenGL Engine\n",
      "Action: emotion: 100%|██████████| 3/3 [00:00<00:00,  6.96it/s]\n",
      "I0000 00:00:1701874276.205776       1 gl_context.cc:344] GL version: 2.1 (2.1 ATI-4.12.7), renderer: AMD Radeon Pro 5300M OpenGL Engine\n",
      "Action: emotion: 100%|██████████| 3/3 [00:00<00:00,  6.98it/s]\n",
      "I0000 00:00:1701874276.704648       1 gl_context.cc:344] GL version: 2.1 (2.1 ATI-4.12.7), renderer: AMD Radeon Pro 5300M OpenGL Engine\n",
      "Action: emotion: 100%|██████████| 3/3 [00:00<00:00,  7.00it/s]\n",
      "I0000 00:00:1701874277.205796       1 gl_context.cc:344] GL version: 2.1 (2.1 ATI-4.12.7), renderer: AMD Radeon Pro 5300M OpenGL Engine\n",
      "Action: emotion: 100%|██████████| 3/3 [00:00<00:00,  6.99it/s]\n",
      "I0000 00:00:1701874277.705300       1 gl_context.cc:344] GL version: 2.1 (2.1 ATI-4.12.7), renderer: AMD Radeon Pro 5300M OpenGL Engine\n",
      "Action: emotion: 100%|██████████| 3/3 [00:00<00:00,  6.94it/s]\n",
      "I0000 00:00:1701874278.207034       1 gl_context.cc:344] GL version: 2.1 (2.1 ATI-4.12.7), renderer: AMD Radeon Pro 5300M OpenGL Engine\n",
      "Action: emotion: 100%|██████████| 3/3 [00:00<00:00,  6.94it/s]\n",
      "I0000 00:00:1701874278.705702       1 gl_context.cc:344] GL version: 2.1 (2.1 ATI-4.12.7), renderer: AMD Radeon Pro 5300M OpenGL Engine\n",
      "Action: emotion: 100%|██████████| 3/3 [00:00<00:00,  7.15it/s]\n",
      "I0000 00:00:1701874279.204997       1 gl_context.cc:344] GL version: 2.1 (2.1 ATI-4.12.7), renderer: AMD Radeon Pro 5300M OpenGL Engine\n",
      "Action: emotion: 100%|██████████| 3/3 [00:00<00:00,  6.13it/s]\n",
      "I0000 00:00:1701874279.769954       1 gl_context.cc:344] GL version: 2.1 (2.1 ATI-4.12.7), renderer: AMD Radeon Pro 5300M OpenGL Engine\n",
      "Action: emotion: 100%|██████████| 3/3 [00:00<00:00,  6.94it/s]\n",
      "I0000 00:00:1701874280.270589       1 gl_context.cc:344] GL version: 2.1 (2.1 ATI-4.12.7), renderer: AMD Radeon Pro 5300M OpenGL Engine\n",
      "Action: emotion: 100%|██████████| 3/3 [00:00<00:00,  6.18it/s]\n",
      "I0000 00:00:1701874280.837375       1 gl_context.cc:344] GL version: 2.1 (2.1 ATI-4.12.7), renderer: AMD Radeon Pro 5300M OpenGL Engine\n",
      "Action: emotion: 100%|██████████| 3/3 [00:00<00:00,  5.58it/s]\n",
      "I0000 00:00:1701874281.437546       1 gl_context.cc:344] GL version: 2.1 (2.1 ATI-4.12.7), renderer: AMD Radeon Pro 5300M OpenGL Engine\n",
      "Action: emotion: 100%|██████████| 3/3 [00:00<00:00,  6.12it/s]\n",
      "I0000 00:00:1701874282.001996       1 gl_context.cc:344] GL version: 2.1 (2.1 ATI-4.12.7), renderer: AMD Radeon Pro 5300M OpenGL Engine\n",
      "Action: emotion: 100%|██████████| 3/3 [00:00<00:00,  5.65it/s]\n",
      "I0000 00:00:1701874282.601757       1 gl_context.cc:344] GL version: 2.1 (2.1 ATI-4.12.7), renderer: AMD Radeon Pro 5300M OpenGL Engine\n",
      "Action: emotion: 100%|██████████| 3/3 [00:00<00:00,  4.92it/s]\n",
      "I0000 00:00:1701874283.268548       1 gl_context.cc:344] GL version: 2.1 (2.1 ATI-4.12.7), renderer: AMD Radeon Pro 5300M OpenGL Engine\n",
      "Action: emotion: 100%|██████████| 3/3 [00:00<00:00,  5.69it/s]\n",
      "I0000 00:00:1701874283.869100       1 gl_context.cc:344] GL version: 2.1 (2.1 ATI-4.12.7), renderer: AMD Radeon Pro 5300M OpenGL Engine\n",
      "Action: emotion: 100%|██████████| 3/3 [00:00<00:00,  6.01it/s]\n",
      "I0000 00:00:1701874284.435654       1 gl_context.cc:344] GL version: 2.1 (2.1 ATI-4.12.7), renderer: AMD Radeon Pro 5300M OpenGL Engine\n",
      "Action: emotion: 100%|██████████| 3/3 [00:00<00:00,  5.86it/s]\n",
      "I0000 00:00:1701874285.034259       1 gl_context.cc:344] GL version: 2.1 (2.1 ATI-4.12.7), renderer: AMD Radeon Pro 5300M OpenGL Engine\n",
      "Action: emotion: 100%|██████████| 3/3 [00:00<00:00,  6.59it/s]\n",
      "I0000 00:00:1701874285.568390       1 gl_context.cc:344] GL version: 2.1 (2.1 ATI-4.12.7), renderer: AMD Radeon Pro 5300M OpenGL Engine\n",
      "Action: emotion: 100%|██████████| 3/3 [00:00<00:00,  6.68it/s]\n",
      "I0000 00:00:1701874286.101471       1 gl_context.cc:344] GL version: 2.1 (2.1 ATI-4.12.7), renderer: AMD Radeon Pro 5300M OpenGL Engine\n",
      "Action: emotion: 100%|██████████| 3/3 [00:00<00:00,  6.34it/s]\n",
      "I0000 00:00:1701874286.634392       1 gl_context.cc:344] GL version: 2.1 (2.1 ATI-4.12.7), renderer: AMD Radeon Pro 5300M OpenGL Engine\n",
      "Action: emotion: 100%|██████████| 3/3 [00:00<00:00,  4.24it/s]\n",
      "I0000 00:00:1701874287.434073       1 gl_context.cc:344] GL version: 2.1 (2.1 ATI-4.12.7), renderer: AMD Radeon Pro 5300M OpenGL Engine\n",
      "Action: emotion: 100%|██████████| 3/3 [00:00<00:00,  5.72it/s]\n",
      "I0000 00:00:1701874288.033572       1 gl_context.cc:344] GL version: 2.1 (2.1 ATI-4.12.7), renderer: AMD Radeon Pro 5300M OpenGL Engine\n",
      "Action: emotion: 100%|██████████| 3/3 [00:00<00:00,  5.14it/s]\n",
      "I0000 00:00:1701874288.699665       1 gl_context.cc:344] GL version: 2.1 (2.1 ATI-4.12.7), renderer: AMD Radeon Pro 5300M OpenGL Engine\n",
      "Action: emotion: 100%|██████████| 3/3 [00:00<00:00,  5.59it/s]\n",
      "I0000 00:00:1701874289.332184       1 gl_context.cc:344] GL version: 2.1 (2.1 ATI-4.12.7), renderer: AMD Radeon Pro 5300M OpenGL Engine\n",
      "Action: emotion: 100%|██████████| 3/3 [00:00<00:00,  4.83it/s]\n",
      "I0000 00:00:1701874290.035708       1 gl_context.cc:344] GL version: 2.1 (2.1 ATI-4.12.7), renderer: AMD Radeon Pro 5300M OpenGL Engine\n",
      "Action: emotion: 100%|██████████| 3/3 [00:00<00:00,  5.47it/s]\n",
      "I0000 00:00:1701874290.665747       1 gl_context.cc:344] GL version: 2.1 (2.1 ATI-4.12.7), renderer: AMD Radeon Pro 5300M OpenGL Engine\n",
      "Action: emotion: 100%|██████████| 3/3 [00:00<00:00,  5.52it/s]\n",
      "I0000 00:00:1701874291.301925       1 gl_context.cc:344] GL version: 2.1 (2.1 ATI-4.12.7), renderer: AMD Radeon Pro 5300M OpenGL Engine\n",
      "Action: emotion: 100%|██████████| 3/3 [00:00<00:00,  5.81it/s]\n",
      "I0000 00:00:1701874291.899063       1 gl_context.cc:344] GL version: 2.1 (2.1 ATI-4.12.7), renderer: AMD Radeon Pro 5300M OpenGL Engine\n",
      "Action: emotion: 100%|██████████| 3/3 [00:00<00:00,  5.57it/s]\n",
      "I0000 00:00:1701874292.532201       1 gl_context.cc:344] GL version: 2.1 (2.1 ATI-4.12.7), renderer: AMD Radeon Pro 5300M OpenGL Engine\n",
      "Action: emotion: 100%|██████████| 3/3 [00:00<00:00,  5.18it/s]\n",
      "I0000 00:00:1701874293.197650       1 gl_context.cc:344] GL version: 2.1 (2.1 ATI-4.12.7), renderer: AMD Radeon Pro 5300M OpenGL Engine\n",
      "Action: gender:  33%|███▎      | 1/3 [00:00<00:00,  3.96it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/josepenaseco/Desktop/dev/vc/p6/p6_vc.ipynb Celda 15\u001b[0m line \u001b[0;36m1\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/josepenaseco/Desktop/dev/vc/p6/p6_vc.ipynb#Y222sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m ret, frame \u001b[39m=\u001b[39m video\u001b[39m.\u001b[39mread()\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/josepenaseco/Desktop/dev/vc/p6/p6_vc.ipynb#Y222sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m faces \u001b[39m=\u001b[39m face_detector\u001b[39m.\u001b[39mdetect(frame)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/josepenaseco/Desktop/dev/vc/p6/p6_vc.ipynb#Y222sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m qualifications \u001b[39m=\u001b[39m [qualifier\u001b[39m.\u001b[39;49mqualify(face) \u001b[39mfor\u001b[39;49;00m face \u001b[39min\u001b[39;49;00m faces]\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/josepenaseco/Desktop/dev/vc/p6/p6_vc.ipynb#Y222sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m display \u001b[39m=\u001b[39m OpenCVFaceQualificationDisplay(qualifications, frame)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/josepenaseco/Desktop/dev/vc/p6/p6_vc.ipynb#Y222sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m display\u001b[39m.\u001b[39mshow()\n",
      "\u001b[1;32m/Users/josepenaseco/Desktop/dev/vc/p6/p6_vc.ipynb Celda 15\u001b[0m line \u001b[0;36m1\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/josepenaseco/Desktop/dev/vc/p6/p6_vc.ipynb#Y222sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m ret, frame \u001b[39m=\u001b[39m video\u001b[39m.\u001b[39mread()\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/josepenaseco/Desktop/dev/vc/p6/p6_vc.ipynb#Y222sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m faces \u001b[39m=\u001b[39m face_detector\u001b[39m.\u001b[39mdetect(frame)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/josepenaseco/Desktop/dev/vc/p6/p6_vc.ipynb#Y222sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m qualifications \u001b[39m=\u001b[39m [qualifier\u001b[39m.\u001b[39;49mqualify(face) \u001b[39mfor\u001b[39;00m face \u001b[39min\u001b[39;00m faces]\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/josepenaseco/Desktop/dev/vc/p6/p6_vc.ipynb#Y222sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m display \u001b[39m=\u001b[39m OpenCVFaceQualificationDisplay(qualifications, frame)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/josepenaseco/Desktop/dev/vc/p6/p6_vc.ipynb#Y222sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m display\u001b[39m.\u001b[39mshow()\n",
      "\u001b[1;32m/Users/josepenaseco/Desktop/dev/vc/p6/p6_vc.ipynb Celda 15\u001b[0m line \u001b[0;36m6\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/josepenaseco/Desktop/dev/vc/p6/p6_vc.ipynb#Y222sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mqualify\u001b[39m(\u001b[39mself\u001b[39m, face_detector_result: FaceDetectorResult) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Person:\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/josepenaseco/Desktop/dev/vc/p6/p6_vc.ipynb#Y222sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m     face_image \u001b[39m=\u001b[39m face_detector_result\u001b[39m.\u001b[39mimage\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/josepenaseco/Desktop/dev/vc/p6/p6_vc.ipynb#Y222sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m     deepface_result \u001b[39m=\u001b[39m DeepFace\u001b[39m.\u001b[39;49manalyze(img_path \u001b[39m=\u001b[39;49m face_image, actions \u001b[39m=\u001b[39;49m [\u001b[39m'\u001b[39;49m\u001b[39mage\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m'\u001b[39;49m\u001b[39mgender\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m'\u001b[39;49m\u001b[39memotion\u001b[39;49m\u001b[39m'\u001b[39;49m], enforce_detection\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)[\u001b[39m0\u001b[39m]\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/josepenaseco/Desktop/dev/vc/p6/p6_vc.ipynb#Y222sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m     age \u001b[39m=\u001b[39m \u001b[39mstr\u001b[39m(deepface_result[\u001b[39m\"\u001b[39m\u001b[39mage\u001b[39m\u001b[39m\"\u001b[39m])\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/josepenaseco/Desktop/dev/vc/p6/p6_vc.ipynb#Y222sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m     gender \u001b[39m=\u001b[39m Genre(\u001b[39mmax\u001b[39m(deepface_result[\u001b[39m\"\u001b[39m\u001b[39mgender\u001b[39m\u001b[39m\"\u001b[39m], key \u001b[39m=\u001b[39m deepface_result[\u001b[39m\"\u001b[39m\u001b[39mgender\u001b[39m\u001b[39m\"\u001b[39m]\u001b[39m.\u001b[39mget))\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.4/lib/python3.11/site-packages/deepface/DeepFace.py:355\u001b[0m, in \u001b[0;36manalyze\u001b[0;34m(img_path, actions, enforce_detection, detector_backend, align, silent)\u001b[0m\n\u001b[1;32m    352\u001b[0m     obj[\u001b[39m\"\u001b[39m\u001b[39mage\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mint\u001b[39m(apparent_age)\n\u001b[1;32m    354\u001b[0m \u001b[39melif\u001b[39;00m action \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mgender\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m--> 355\u001b[0m     gender_predictions \u001b[39m=\u001b[39m models[\u001b[39m\"\u001b[39;49m\u001b[39mgender\u001b[39;49m\u001b[39m\"\u001b[39;49m]\u001b[39m.\u001b[39;49mpredict(img_content, verbose\u001b[39m=\u001b[39;49m\u001b[39m0\u001b[39;49m)[\u001b[39m0\u001b[39m, :]\n\u001b[1;32m    356\u001b[0m     obj[\u001b[39m\"\u001b[39m\u001b[39mgender\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m {}\n\u001b[1;32m    357\u001b[0m     \u001b[39mfor\u001b[39;00m i, gender_label \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(Gender\u001b[39m.\u001b[39mlabels):\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.4/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     66\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.4/lib/python3.11/site-packages/keras/src/engine/training.py:2596\u001b[0m, in \u001b[0;36mModel.predict\u001b[0;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   2587\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mValueError\u001b[39;00m:\n\u001b[1;32m   2588\u001b[0m         warnings\u001b[39m.\u001b[39mwarn(\n\u001b[1;32m   2589\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mUsing Model.predict with MultiWorkerMirroredStrategy \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   2590\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mor TPUStrategy and AutoShardPolicy.FILE might lead to \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2593\u001b[0m             stacklevel\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m,\n\u001b[1;32m   2594\u001b[0m         )\n\u001b[0;32m-> 2596\u001b[0m data_handler \u001b[39m=\u001b[39m data_adapter\u001b[39m.\u001b[39;49mget_data_handler(\n\u001b[1;32m   2597\u001b[0m     x\u001b[39m=\u001b[39;49mx,\n\u001b[1;32m   2598\u001b[0m     batch_size\u001b[39m=\u001b[39;49mbatch_size,\n\u001b[1;32m   2599\u001b[0m     steps_per_epoch\u001b[39m=\u001b[39;49msteps,\n\u001b[1;32m   2600\u001b[0m     initial_epoch\u001b[39m=\u001b[39;49m\u001b[39m0\u001b[39;49m,\n\u001b[1;32m   2601\u001b[0m     epochs\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m,\n\u001b[1;32m   2602\u001b[0m     max_queue_size\u001b[39m=\u001b[39;49mmax_queue_size,\n\u001b[1;32m   2603\u001b[0m     workers\u001b[39m=\u001b[39;49mworkers,\n\u001b[1;32m   2604\u001b[0m     use_multiprocessing\u001b[39m=\u001b[39;49muse_multiprocessing,\n\u001b[1;32m   2605\u001b[0m     model\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m,\n\u001b[1;32m   2606\u001b[0m     steps_per_execution\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_steps_per_execution,\n\u001b[1;32m   2607\u001b[0m )\n\u001b[1;32m   2609\u001b[0m \u001b[39m# Container that configures and calls `tf.keras.Callback`s.\u001b[39;00m\n\u001b[1;32m   2610\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(callbacks, callbacks_module\u001b[39m.\u001b[39mCallbackList):\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.4/lib/python3.11/site-packages/keras/src/engine/data_adapter.py:1688\u001b[0m, in \u001b[0;36mget_data_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1686\u001b[0m         \u001b[39mreturn\u001b[39;00m _ClusterCoordinatorExactEvalDataHandler(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m   1687\u001b[0m     \u001b[39mreturn\u001b[39;00m _ClusterCoordinatorDataHandler(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m-> 1688\u001b[0m \u001b[39mreturn\u001b[39;00m DataHandler(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.4/lib/python3.11/site-packages/keras/src/engine/data_adapter.py:1292\u001b[0m, in \u001b[0;36mDataHandler.__init__\u001b[0;34m(self, x, y, sample_weight, batch_size, steps_per_epoch, initial_epoch, epochs, shuffle, class_weight, max_queue_size, workers, use_multiprocessing, model, steps_per_execution, distribute, pss_evaluation_shards)\u001b[0m\n\u001b[1;32m   1289\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_steps_per_execution \u001b[39m=\u001b[39m steps_per_execution\n\u001b[1;32m   1291\u001b[0m adapter_cls \u001b[39m=\u001b[39m select_data_adapter(x, y)\n\u001b[0;32m-> 1292\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_adapter \u001b[39m=\u001b[39m adapter_cls(\n\u001b[1;32m   1293\u001b[0m     x,\n\u001b[1;32m   1294\u001b[0m     y,\n\u001b[1;32m   1295\u001b[0m     batch_size\u001b[39m=\u001b[39;49mbatch_size,\n\u001b[1;32m   1296\u001b[0m     steps\u001b[39m=\u001b[39;49msteps_per_epoch,\n\u001b[1;32m   1297\u001b[0m     epochs\u001b[39m=\u001b[39;49mepochs \u001b[39m-\u001b[39;49m initial_epoch,\n\u001b[1;32m   1298\u001b[0m     sample_weights\u001b[39m=\u001b[39;49msample_weight,\n\u001b[1;32m   1299\u001b[0m     shuffle\u001b[39m=\u001b[39;49mshuffle,\n\u001b[1;32m   1300\u001b[0m     max_queue_size\u001b[39m=\u001b[39;49mmax_queue_size,\n\u001b[1;32m   1301\u001b[0m     workers\u001b[39m=\u001b[39;49mworkers,\n\u001b[1;32m   1302\u001b[0m     use_multiprocessing\u001b[39m=\u001b[39;49muse_multiprocessing,\n\u001b[1;32m   1303\u001b[0m     distribution_strategy\u001b[39m=\u001b[39;49mtf\u001b[39m.\u001b[39;49mdistribute\u001b[39m.\u001b[39;49mget_strategy(),\n\u001b[1;32m   1304\u001b[0m     model\u001b[39m=\u001b[39;49mmodel,\n\u001b[1;32m   1305\u001b[0m     pss_evaluation_shards\u001b[39m=\u001b[39;49mpss_evaluation_shards,\n\u001b[1;32m   1306\u001b[0m )\n\u001b[1;32m   1308\u001b[0m strategy \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mdistribute\u001b[39m.\u001b[39mget_strategy()\n\u001b[1;32m   1310\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_current_step \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.4/lib/python3.11/site-packages/keras/src/engine/data_adapter.py:314\u001b[0m, in \u001b[0;36mTensorLikeDataAdapter.__init__\u001b[0;34m(self, x, y, sample_weights, sample_weight_modes, batch_size, epochs, steps, shuffle, **kwargs)\u001b[0m\n\u001b[1;32m    307\u001b[0m     \u001b[39mreturn\u001b[39;00m indices\n\u001b[1;32m    309\u001b[0m \u001b[39m# We prefetch a single element. Computing large permutations can take\u001b[39;00m\n\u001b[1;32m    310\u001b[0m \u001b[39m# quite a while so we don't want to wait for prefetching over an epoch\u001b[39;00m\n\u001b[1;32m    311\u001b[0m \u001b[39m# boundary to trigger the next permutation. On the other hand, too many\u001b[39;00m\n\u001b[1;32m    312\u001b[0m \u001b[39m# simultaneous shuffles can contend on a hardware level and degrade all\u001b[39;00m\n\u001b[1;32m    313\u001b[0m \u001b[39m# performance.\u001b[39;00m\n\u001b[0;32m--> 314\u001b[0m indices_dataset \u001b[39m=\u001b[39m indices_dataset\u001b[39m.\u001b[39;49mmap(permutation)\u001b[39m.\u001b[39mprefetch(\u001b[39m1\u001b[39m)\n\u001b[1;32m    316\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mslice_batch_indices\u001b[39m(indices):\n\u001b[1;32m    317\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Convert a Tensor of indices into a dataset of batched indices.\u001b[39;00m\n\u001b[1;32m    318\u001b[0m \n\u001b[1;32m    319\u001b[0m \u001b[39m    This step can be accomplished in several ways. The most natural is\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    331\u001b[0m \u001b[39m      A Dataset of batched indices.\u001b[39;00m\n\u001b[1;32m    332\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.4/lib/python3.11/site-packages/tensorflow/python/data/ops/dataset_ops.py:2268\u001b[0m, in \u001b[0;36mDatasetV2.map\u001b[0;34m(self, map_func, num_parallel_calls, deterministic, name)\u001b[0m\n\u001b[1;32m   2264\u001b[0m \u001b[39m# Loaded lazily due to a circular dependency (dataset_ops -> map_op ->\u001b[39;00m\n\u001b[1;32m   2265\u001b[0m \u001b[39m# dataset_ops).\u001b[39;00m\n\u001b[1;32m   2266\u001b[0m \u001b[39m# pylint: disable=g-import-not-at-top,protected-access\u001b[39;00m\n\u001b[1;32m   2267\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdata\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mops\u001b[39;00m \u001b[39mimport\u001b[39;00m map_op\n\u001b[0;32m-> 2268\u001b[0m \u001b[39mreturn\u001b[39;00m map_op\u001b[39m.\u001b[39;49m_map_v2(\n\u001b[1;32m   2269\u001b[0m     \u001b[39mself\u001b[39;49m,\n\u001b[1;32m   2270\u001b[0m     map_func,\n\u001b[1;32m   2271\u001b[0m     num_parallel_calls\u001b[39m=\u001b[39;49mnum_parallel_calls,\n\u001b[1;32m   2272\u001b[0m     deterministic\u001b[39m=\u001b[39;49mdeterministic,\n\u001b[1;32m   2273\u001b[0m     name\u001b[39m=\u001b[39;49mname)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.4/lib/python3.11/site-packages/tensorflow/python/data/ops/map_op.py:37\u001b[0m, in \u001b[0;36m_map_v2\u001b[0;34m(input_dataset, map_func, num_parallel_calls, deterministic, name)\u001b[0m\n\u001b[1;32m     34\u001b[0m   \u001b[39mif\u001b[39;00m deterministic \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m debug_mode\u001b[39m.\u001b[39mDEBUG_MODE:\n\u001b[1;32m     35\u001b[0m     warnings\u001b[39m.\u001b[39mwarn(\u001b[39m\"\u001b[39m\u001b[39mThe `deterministic` argument has no effect unless the \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m     36\u001b[0m                   \u001b[39m\"\u001b[39m\u001b[39m`num_parallel_calls` argument is specified.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m---> 37\u001b[0m   \u001b[39mreturn\u001b[39;00m _MapDataset(\n\u001b[1;32m     38\u001b[0m       input_dataset, map_func, preserve_cardinality\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, name\u001b[39m=\u001b[39;49mname)\n\u001b[1;32m     39\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     40\u001b[0m   \u001b[39mreturn\u001b[39;00m _ParallelMapDataset(\n\u001b[1;32m     41\u001b[0m       input_dataset,\n\u001b[1;32m     42\u001b[0m       map_func,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     45\u001b[0m       preserve_cardinality\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m,\n\u001b[1;32m     46\u001b[0m       name\u001b[39m=\u001b[39mname)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.4/lib/python3.11/site-packages/tensorflow/python/data/ops/map_op.py:107\u001b[0m, in \u001b[0;36m_MapDataset.__init__\u001b[0;34m(self, input_dataset, map_func, use_inter_op_parallelism, preserve_cardinality, use_legacy_function, name)\u001b[0m\n\u001b[1;32m    105\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_use_inter_op_parallelism \u001b[39m=\u001b[39m use_inter_op_parallelism\n\u001b[1;32m    106\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_preserve_cardinality \u001b[39m=\u001b[39m preserve_cardinality\n\u001b[0;32m--> 107\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_map_func \u001b[39m=\u001b[39m structured_function\u001b[39m.\u001b[39;49mStructuredFunctionWrapper(\n\u001b[1;32m    108\u001b[0m     map_func,\n\u001b[1;32m    109\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_transformation_name(),\n\u001b[1;32m    110\u001b[0m     dataset\u001b[39m=\u001b[39;49minput_dataset,\n\u001b[1;32m    111\u001b[0m     use_legacy_function\u001b[39m=\u001b[39;49muse_legacy_function)\n\u001b[1;32m    112\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_name \u001b[39m=\u001b[39m name\n\u001b[1;32m    113\u001b[0m variant_tensor \u001b[39m=\u001b[39m gen_dataset_ops\u001b[39m.\u001b[39mmap_dataset(\n\u001b[1;32m    114\u001b[0m     input_dataset\u001b[39m.\u001b[39m_variant_tensor,  \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m    115\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_map_func\u001b[39m.\u001b[39mfunction\u001b[39m.\u001b[39mcaptured_inputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    118\u001b[0m     preserve_cardinality\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_preserve_cardinality,\n\u001b[1;32m    119\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_common_args)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.4/lib/python3.11/site-packages/tensorflow/python/data/ops/structured_function.py:265\u001b[0m, in \u001b[0;36mStructuredFunctionWrapper.__init__\u001b[0;34m(self, func, transformation_name, dataset, input_classes, input_shapes, input_types, input_structure, add_to_graph, use_legacy_function, defun_kwargs)\u001b[0m\n\u001b[1;32m    258\u001b[0m       warnings\u001b[39m.\u001b[39mwarn(\n\u001b[1;32m    259\u001b[0m           \u001b[39m\"\u001b[39m\u001b[39mEven though the `tf.config.experimental_run_functions_eagerly` \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    260\u001b[0m           \u001b[39m\"\u001b[39m\u001b[39moption is set, this option does not apply to tf.data functions. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    261\u001b[0m           \u001b[39m\"\u001b[39m\u001b[39mTo force eager execution of tf.data functions, please use \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    262\u001b[0m           \u001b[39m\"\u001b[39m\u001b[39m`tf.data.experimental.enable_debug_mode()`.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    263\u001b[0m     fn_factory \u001b[39m=\u001b[39m trace_tf_function(defun_kwargs)\n\u001b[0;32m--> 265\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_function \u001b[39m=\u001b[39m fn_factory()\n\u001b[1;32m    266\u001b[0m \u001b[39m# There is no graph to add in eager mode.\u001b[39;00m\n\u001b[1;32m    267\u001b[0m add_to_graph \u001b[39m&\u001b[39m\u001b[39m=\u001b[39m \u001b[39mnot\u001b[39;00m context\u001b[39m.\u001b[39mexecuting_eagerly()\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.4/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:1222\u001b[0m, in \u001b[0;36mFunction.get_concrete_function\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1220\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget_concrete_function\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m   1221\u001b[0m   \u001b[39m# Implements GenericFunction.get_concrete_function.\u001b[39;00m\n\u001b[0;32m-> 1222\u001b[0m   concrete \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_concrete_function_garbage_collected(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1223\u001b[0m   concrete\u001b[39m.\u001b[39m_garbage_collector\u001b[39m.\u001b[39mrelease()  \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m   1224\u001b[0m   \u001b[39mreturn\u001b[39;00m concrete\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.4/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:1192\u001b[0m, in \u001b[0;36mFunction._get_concrete_function_garbage_collected\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1190\u001b[0m   \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_variable_creation_config \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m   1191\u001b[0m     initializers \u001b[39m=\u001b[39m []\n\u001b[0;32m-> 1192\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_initialize(args, kwargs, add_initializers_to\u001b[39m=\u001b[39;49minitializers)\n\u001b[1;32m   1193\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_initialize_uninitialized_variables(initializers)\n\u001b[1;32m   1195\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_created_variables:\n\u001b[1;32m   1196\u001b[0m   \u001b[39m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[1;32m   1197\u001b[0m   \u001b[39m# version which is guaranteed to never create variables.\u001b[39;00m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.4/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:694\u001b[0m, in \u001b[0;36mFunction._initialize\u001b[0;34m(self, args, kwds, add_initializers_to)\u001b[0m\n\u001b[1;32m    689\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_variable_creation_config \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_generate_scoped_tracing_options(\n\u001b[1;32m    690\u001b[0m     variable_capturing_scope,\n\u001b[1;32m    691\u001b[0m     tracing_compilation\u001b[39m.\u001b[39mScopeType\u001b[39m.\u001b[39mVARIABLE_CREATION,\n\u001b[1;32m    692\u001b[0m )\n\u001b[1;32m    693\u001b[0m \u001b[39m# Force the definition of the function for these arguments\u001b[39;00m\n\u001b[0;32m--> 694\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_concrete_variable_creation_fn \u001b[39m=\u001b[39m tracing_compilation\u001b[39m.\u001b[39;49mtrace_function(\n\u001b[1;32m    695\u001b[0m     args, kwds, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_variable_creation_config\n\u001b[1;32m    696\u001b[0m )\n\u001b[1;32m    698\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39minvalid_creator_scope\u001b[39m(\u001b[39m*\u001b[39munused_args, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39munused_kwds):\n\u001b[1;32m    699\u001b[0m \u001b[39m  \u001b[39m\u001b[39m\"\"\"Disables variable creation.\"\"\"\u001b[39;00m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.4/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py:178\u001b[0m, in \u001b[0;36mtrace_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    175\u001b[0m     args \u001b[39m=\u001b[39m tracing_options\u001b[39m.\u001b[39minput_signature\n\u001b[1;32m    176\u001b[0m     kwargs \u001b[39m=\u001b[39m {}\n\u001b[0;32m--> 178\u001b[0m   concrete_function \u001b[39m=\u001b[39m _maybe_define_function(\n\u001b[1;32m    179\u001b[0m       args, kwargs, tracing_options\n\u001b[1;32m    180\u001b[0m   )\n\u001b[1;32m    181\u001b[0m   _set_arg_keywords(concrete_function)\n\u001b[1;32m    183\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m tracing_options\u001b[39m.\u001b[39mbind_graph_to_function:\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.4/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py:284\u001b[0m, in \u001b[0;36m_maybe_define_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    282\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    283\u001b[0m   target_func_type \u001b[39m=\u001b[39m lookup_func_type\n\u001b[0;32m--> 284\u001b[0m concrete_function \u001b[39m=\u001b[39m _create_concrete_function(\n\u001b[1;32m    285\u001b[0m     target_func_type, lookup_func_context, func_graph, tracing_options\n\u001b[1;32m    286\u001b[0m )\n\u001b[1;32m    288\u001b[0m \u001b[39mif\u001b[39;00m tracing_options\u001b[39m.\u001b[39mfunction_cache \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    289\u001b[0m   tracing_options\u001b[39m.\u001b[39mfunction_cache\u001b[39m.\u001b[39madd(\n\u001b[1;32m    290\u001b[0m       concrete_function, current_func_context\n\u001b[1;32m    291\u001b[0m   )\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.4/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py:337\u001b[0m, in \u001b[0;36m_create_concrete_function\u001b[0;34m(function_type, type_context, func_graph, tracing_options)\u001b[0m\n\u001b[1;32m    328\u001b[0m output_type \u001b[39m=\u001b[39m trace_type\u001b[39m.\u001b[39mfrom_value(\n\u001b[1;32m    329\u001b[0m     traced_func_graph\u001b[39m.\u001b[39mstructured_outputs, type_context\n\u001b[1;32m    330\u001b[0m )\n\u001b[1;32m    331\u001b[0m traced_func_type \u001b[39m=\u001b[39m function_type_lib\u001b[39m.\u001b[39mFunctionType(\n\u001b[1;32m    332\u001b[0m     function_type\u001b[39m.\u001b[39mparameters\u001b[39m.\u001b[39mvalues(),\n\u001b[1;32m    333\u001b[0m     traced_func_graph\u001b[39m.\u001b[39mfunction_captures\u001b[39m.\u001b[39mcapture_types,\n\u001b[1;32m    334\u001b[0m     return_annotation\u001b[39m=\u001b[39moutput_type,\n\u001b[1;32m    335\u001b[0m )\n\u001b[0;32m--> 337\u001b[0m concrete_function \u001b[39m=\u001b[39m concrete_function_lib\u001b[39m.\u001b[39;49mConcreteFunction\u001b[39m.\u001b[39;49mfrom_func_graph(\n\u001b[1;32m    338\u001b[0m     traced_func_graph,\n\u001b[1;32m    339\u001b[0m     traced_func_type,\n\u001b[1;32m    340\u001b[0m     tracing_options\u001b[39m.\u001b[39;49mattributes,\n\u001b[1;32m    341\u001b[0m     \u001b[39m# Tell the ConcreteFunction to clean up its graph once it goes out of\u001b[39;49;00m\n\u001b[1;32m    342\u001b[0m     \u001b[39m# scope. This is not the default behavior since it gets used in some\u001b[39;49;00m\n\u001b[1;32m    343\u001b[0m     \u001b[39m# places (like Keras) where the FuncGraph lives longer than the\u001b[39;49;00m\n\u001b[1;32m    344\u001b[0m     \u001b[39m# ConcreteFunction.\u001b[39;49;00m\n\u001b[1;32m    345\u001b[0m     shared_func_graph\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m    346\u001b[0m )\n\u001b[1;32m    348\u001b[0m transform\u001b[39m.\u001b[39mcall_concrete_function_callbacks(concrete_function)\n\u001b[1;32m    350\u001b[0m \u001b[39mreturn\u001b[39;00m concrete_function\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.4/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py:1025\u001b[0m, in \u001b[0;36mConcreteFunction.from_func_graph\u001b[0;34m(cls, graph, function_type, attrs, shared_func_graph)\u001b[0m\n\u001b[1;32m   1020\u001b[0m \u001b[39m@classmethod\u001b[39m\n\u001b[1;32m   1021\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfrom_func_graph\u001b[39m(\u001b[39mcls\u001b[39m, graph, function_type, attrs, shared_func_graph\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m):\n\u001b[1;32m   1022\u001b[0m   atomic_fn \u001b[39m=\u001b[39m atomic_function\u001b[39m.\u001b[39mfrom_func_graph(\n\u001b[1;32m   1023\u001b[0m       _inference_name(graph\u001b[39m.\u001b[39mname), graph, attrs, function_type\n\u001b[1;32m   1024\u001b[0m   )\n\u001b[0;32m-> 1025\u001b[0m   \u001b[39mreturn\u001b[39;00m ConcreteFunction(atomic_fn, shared_func_graph\u001b[39m=\u001b[39;49mshared_func_graph)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.4/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py:998\u001b[0m, in \u001b[0;36mConcreteFunction.__init__\u001b[0;34m(self, atomic_fn, shared_func_graph)\u001b[0m\n\u001b[1;32m    993\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_function_type \u001b[39m=\u001b[39m atomic_fn\u001b[39m.\u001b[39mfunction_type\n\u001b[1;32m    995\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_output_shapes \u001b[39m=\u001b[39m \u001b[39mtuple\u001b[39m(\n\u001b[1;32m    996\u001b[0m     output\u001b[39m.\u001b[39mshape \u001b[39mfor\u001b[39;00m output \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_func_graph\u001b[39m.\u001b[39moutputs)\n\u001b[1;32m    997\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_attrs \u001b[39m=\u001b[39m attributes_lib\u001b[39m.\u001b[39mparse_func_attrs(\n\u001b[0;32m--> 998\u001b[0m     atomic_fn\u001b[39m.\u001b[39;49mattributes \u001b[39mor\u001b[39;00m {}\n\u001b[1;32m    999\u001b[0m )\n\u001b[1;32m   1001\u001b[0m \u001b[39mif\u001b[39;00m shared_func_graph:\n\u001b[1;32m   1002\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_garbage_collector \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.4/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:150\u001b[0m, in \u001b[0;36mAtomicFunction.attributes\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    147\u001b[0m \u001b[39m@property\u001b[39m\n\u001b[1;32m    148\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mattributes\u001b[39m(\u001b[39mself\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Any:\n\u001b[1;32m    149\u001b[0m \u001b[39m  \u001b[39m\u001b[39m\"\"\"Returns FunctionDef attributes in the Runtime.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 150\u001b[0m   attrs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdefinition\u001b[39m.\u001b[39mattr\n\u001b[1;32m    151\u001b[0m   \u001b[39m# Remove construction context since it is specific to runtime and this fn.\u001b[39;00m\n\u001b[1;32m    152\u001b[0m   attrs\u001b[39m.\u001b[39mpop(attributes_lib\u001b[39m.\u001b[39mEAGER_RUNTIME_CONSTRUCTION_CONTEXT, \u001b[39mNone\u001b[39;00m)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.4/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:145\u001b[0m, in \u001b[0;36mAtomicFunction.definition\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    142\u001b[0m \u001b[39m@property\u001b[39m\n\u001b[1;32m    143\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdefinition\u001b[39m(\u001b[39mself\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m function_pb2\u001b[39m.\u001b[39mFunctionDef:\n\u001b[1;32m    144\u001b[0m \u001b[39m  \u001b[39m\u001b[39m\"\"\"Current FunctionDef in the Runtime.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 145\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_bound_context\u001b[39m.\u001b[39;49mget_function_def(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mname)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.4/lib/python3.11/site-packages/tensorflow/python/eager/context.py:1391\u001b[0m, in \u001b[0;36mContext.get_function_def\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1389\u001b[0m   proto_data \u001b[39m=\u001b[39m pywrap_tf_session\u001b[39m.\u001b[39mTF_GetBuffer(buffer_)\n\u001b[1;32m   1390\u001b[0m function_def \u001b[39m=\u001b[39m function_pb2\u001b[39m.\u001b[39mFunctionDef()\n\u001b[0;32m-> 1391\u001b[0m function_def\u001b[39m.\u001b[39;49mParseFromString(proto_data)\n\u001b[1;32m   1393\u001b[0m \u001b[39mreturn\u001b[39;00m function_def\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.4/lib/python3.11/site-packages/google/protobuf/message.py:202\u001b[0m, in \u001b[0;36mMessage.ParseFromString\u001b[0;34m(self, serialized)\u001b[0m\n\u001b[1;32m    194\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Parse serialized protocol buffer data into this message.\u001b[39;00m\n\u001b[1;32m    195\u001b[0m \n\u001b[1;32m    196\u001b[0m \u001b[39mLike :func:`MergeFromString()`, except we clear the object first.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    199\u001b[0m \u001b[39m  message.DecodeError if the input cannot be parsed.\u001b[39;00m\n\u001b[1;32m    200\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    201\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mClear()\n\u001b[0;32m--> 202\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mMergeFromString(serialized)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.4/lib/python3.11/site-packages/google/protobuf/internal/python_message.py:1128\u001b[0m, in \u001b[0;36m_AddMergeFromStringMethod.<locals>.MergeFromString\u001b[0;34m(self, serialized)\u001b[0m\n\u001b[1;32m   1126\u001b[0m length \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(serialized)\n\u001b[1;32m   1127\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 1128\u001b[0m   \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_InternalParse(serialized, \u001b[39m0\u001b[39;49m, length) \u001b[39m!=\u001b[39m length:\n\u001b[1;32m   1129\u001b[0m     \u001b[39m# The only reason _InternalParse would return early is if it\u001b[39;00m\n\u001b[1;32m   1130\u001b[0m     \u001b[39m# encountered an end-group tag.\u001b[39;00m\n\u001b[1;32m   1131\u001b[0m     \u001b[39mraise\u001b[39;00m message_mod\u001b[39m.\u001b[39mDecodeError(\u001b[39m'\u001b[39m\u001b[39mUnexpected end-group tag.\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m   1132\u001b[0m \u001b[39mexcept\u001b[39;00m (\u001b[39mIndexError\u001b[39;00m, \u001b[39mTypeError\u001b[39;00m):\n\u001b[1;32m   1133\u001b[0m   \u001b[39m# Now ord(buf[p:p+1]) == ord('') gets TypeError.\u001b[39;00m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.4/lib/python3.11/site-packages/google/protobuf/internal/python_message.py:1195\u001b[0m, in \u001b[0;36m_AddMergeFromStringMethod.<locals>.InternalParse\u001b[0;34m(self, buffer, pos, end)\u001b[0m\n\u001b[1;32m   1193\u001b[0m   pos \u001b[39m=\u001b[39m new_pos\n\u001b[1;32m   1194\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1195\u001b[0m   pos \u001b[39m=\u001b[39m field_decoder(buffer, new_pos, end, \u001b[39mself\u001b[39;49m, field_dict)\n\u001b[1;32m   1196\u001b[0m   \u001b[39mif\u001b[39;00m field_desc:\n\u001b[1;32m   1197\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_UpdateOneofState(field_desc)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.4/lib/python3.11/site-packages/google/protobuf/internal/decoder.py:705\u001b[0m, in \u001b[0;36mMessageDecoder.<locals>.DecodeRepeatedField\u001b[0;34m(buffer, pos, end, message, field_dict)\u001b[0m\n\u001b[1;32m    703\u001b[0m   \u001b[39mraise\u001b[39;00m _DecodeError(\u001b[39m'\u001b[39m\u001b[39mTruncated message.\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m    704\u001b[0m \u001b[39m# Read sub-message.\u001b[39;00m\n\u001b[0;32m--> 705\u001b[0m \u001b[39mif\u001b[39;00m value\u001b[39m.\u001b[39;49madd()\u001b[39m.\u001b[39;49m_InternalParse(buffer, pos, new_pos) \u001b[39m!=\u001b[39m new_pos:\n\u001b[1;32m    706\u001b[0m   \u001b[39m# The only reason _InternalParse would return early is if it\u001b[39;00m\n\u001b[1;32m    707\u001b[0m   \u001b[39m# encountered an end-group tag.\u001b[39;00m\n\u001b[1;32m    708\u001b[0m   \u001b[39mraise\u001b[39;00m _DecodeError(\u001b[39m'\u001b[39m\u001b[39mUnexpected end-group tag.\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m    709\u001b[0m \u001b[39m# Predict that the next tag is another copy of the same repeated field.\u001b[39;00m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.4/lib/python3.11/site-packages/google/protobuf/internal/python_message.py:1195\u001b[0m, in \u001b[0;36m_AddMergeFromStringMethod.<locals>.InternalParse\u001b[0;34m(self, buffer, pos, end)\u001b[0m\n\u001b[1;32m   1193\u001b[0m   pos \u001b[39m=\u001b[39m new_pos\n\u001b[1;32m   1194\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1195\u001b[0m   pos \u001b[39m=\u001b[39m field_decoder(buffer, new_pos, end, \u001b[39mself\u001b[39;49m, field_dict)\n\u001b[1;32m   1196\u001b[0m   \u001b[39mif\u001b[39;00m field_desc:\n\u001b[1;32m   1197\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_UpdateOneofState(field_desc)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.4/lib/python3.11/site-packages/google/protobuf/internal/decoder.py:860\u001b[0m, in \u001b[0;36mMapDecoder.<locals>.DecodeMap\u001b[0;34m(buffer, pos, end, message, field_dict)\u001b[0m\n\u001b[1;32m    858\u001b[0m \u001b[39m# Read sub-message.\u001b[39;00m\n\u001b[1;32m    859\u001b[0m submsg\u001b[39m.\u001b[39mClear()\n\u001b[0;32m--> 860\u001b[0m \u001b[39mif\u001b[39;00m submsg\u001b[39m.\u001b[39;49m_InternalParse(buffer, pos, new_pos) \u001b[39m!=\u001b[39m new_pos:\n\u001b[1;32m    861\u001b[0m   \u001b[39m# The only reason _InternalParse would return early is if it\u001b[39;00m\n\u001b[1;32m    862\u001b[0m   \u001b[39m# encountered an end-group tag.\u001b[39;00m\n\u001b[1;32m    863\u001b[0m   \u001b[39mraise\u001b[39;00m _DecodeError(\u001b[39m'\u001b[39m\u001b[39mUnexpected end-group tag.\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m    865\u001b[0m \u001b[39mif\u001b[39;00m is_message_map:\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.4/lib/python3.11/site-packages/google/protobuf/internal/python_message.py:1165\u001b[0m, in \u001b[0;36m_AddMergeFromStringMethod.<locals>.InternalParse\u001b[0;34m(self, buffer, pos, end)\u001b[0m\n\u001b[1;32m   1163\u001b[0m \u001b[39mwhile\u001b[39;00m pos \u001b[39m!=\u001b[39m end:\n\u001b[1;32m   1164\u001b[0m   (tag_bytes, new_pos) \u001b[39m=\u001b[39m local_ReadTag(buffer, pos)\n\u001b[0;32m-> 1165\u001b[0m   field_decoder, field_desc \u001b[39m=\u001b[39m decoders_by_tag\u001b[39m.\u001b[39mget(tag_bytes, (\u001b[39mNone\u001b[39;00m, \u001b[39mNone\u001b[39;00m))\n\u001b[1;32m   1166\u001b[0m   \u001b[39mif\u001b[39;00m field_decoder \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m   1167\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_unknown_fields:   \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import cv2 as cv\n",
    "\n",
    "video = cv.VideoCapture(0)\n",
    "face_detector = MediaPipeFaceDetector()\n",
    "qualifier = DeepfaceFaceQualifier()\n",
    "\n",
    "while True:\n",
    "    ret, frame = video.read()\n",
    "    faces = face_detector.detect(frame)\n",
    "    qualifications = [qualifier.qualify(face) for face in faces]\n",
    "    display = OpenCVFaceQualificationDisplay(qualifications, frame)\n",
    "    display.show()\n",
    "\n",
    "    cv.imshow('Video', frame)\n",
    "\n",
    "    if cv.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "video.release()\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FACE AUTHENTICATOR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AuthenticationScreen(ABC):\n",
    "    @abstractmethod\n",
    "    def display(self) -> None:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Callable\n",
    "from functools import reduce\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class Transition:\n",
    "    next_state : str\n",
    "    actions: List[Callable[[], bool]]\n",
    "\n",
    "    @staticmethod\n",
    "    def to(next_state : str) -> 'Transition':\n",
    "        return Transition(next_state, [])\n",
    "\n",
    "    def when(self, action : Callable[[], bool]) -> 'Transition':\n",
    "        self.actions.append(action)\n",
    "        return self\n",
    "\n",
    "    def evaluate_transition(self) -> bool:\n",
    "        for action in self.actions:\n",
    "            if action():\n",
    "                return True\n",
    "        return False\n",
    "\n",
    "class AuthenticationScreen(ABC):\n",
    "    @abstractmethod\n",
    "    def display(self) -> None:\n",
    "        pass\n",
    "    \n",
    "@dataclass\n",
    "class State:\n",
    "    is_initial : bool\n",
    "    name : str\n",
    "    screen : Callable[[], AuthenticationScreen]\n",
    "    transitions : List[Transition]\n",
    "    on_enter : Callable[[np.ndarray], None] = lambda frame: None\n",
    "    on_exit : Callable[[np.ndarray], None] = lambda frame: None\n",
    "\n",
    "    @staticmethod\n",
    "    def default(name : str, screen : Callable[[np.ndarray], AuthenticationScreen]) -> 'State':\n",
    "        return State(True, name, screen, [])\n",
    "    \n",
    "    @staticmethod\n",
    "    def of(name : str, screen : Callable[[np.ndarray], AuthenticationScreen]) -> 'State':\n",
    "        return State(False, name, screen, [])\n",
    "\n",
    "    def do(self, transition : Transition) -> 'State':\n",
    "        self.transitions.append(transition)\n",
    "        return self\n",
    "    \n",
    "    def do_on_enter(self, action : Callable[[], None]) -> 'State':\n",
    "        self.on_enter = action\n",
    "        return self\n",
    "\n",
    "@dataclass\n",
    "class FaceComparatorResult:\n",
    "    similarity: float\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "\n",
    "class StateMachine(ABC):\n",
    "    class Builder:\n",
    "        def __init__(self) -> None:\n",
    "            self.states = []\n",
    "        \n",
    "        def add_state(self, state : State) -> 'Builder':\n",
    "            self.states.append(state)\n",
    "            return self\n",
    "        \n",
    "        def build(self) -> 'StateMachine':\n",
    "            return StateMachine(self.states)\n",
    "    \n",
    "    @staticmethod\n",
    "    def start_building() -> Builder:\n",
    "        return StateMachine.Builder()\n",
    "\n",
    "    def __init__(self, states: List[State] ) -> None:\n",
    "        self.states = states\n",
    "        self.current_state = list(filter(lambda x: x.is_initial, states))[0]\n",
    "        self.current_state.on_enter(frame)\n",
    "    \n",
    "    def execute(self, frame : np.array):\n",
    "        self.current_state.screen(frame).display()\n",
    "        self.evaluate_conditions(frame)\n",
    "    \n",
    "    def evaluate_conditions(self, frame) -> None:\n",
    "        for transition in self.current_state.transitions:\n",
    "            if transition.evaluate_transition():\n",
    "                self.current_state.on_exit(frame)\n",
    "                self.current_state = list(filter(lambda x: x.name == transition.next_state, self.states))[0]\n",
    "                self.current_state.on_enter(frame)\n",
    "                break\n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# INFRAESTRUCTURE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FaceComparator:\n",
    "    def compare(self, first_face: FaceDetectorResult, second_face: FaceDetectorResult) -> FaceComparatorResult:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "from deepface import DeepFace\n",
    "\n",
    "class DeepfaceFaceComparator(FaceComparator):\n",
    "    def compare(self, first_face, second_face):\n",
    "        input_image = first_face.image\n",
    "        comparator_image = second_face.image\n",
    "        result = DeepFace.verify(img1_path=input_image, img2_path=comparator_image, enforce_detection=False)\n",
    "        print(result)\n",
    "        return FaceComparatorResult(result[\"distance\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class IconAuthenticationScreen(AuthenticationScreen):\n",
    "    def __init__(self, frame : np.ndarray, icon_path : str, color : tuple, text : str, bg_color : str = None, alpha : float = 0.15) -> None:\n",
    "        self.frame = frame\n",
    "        self.icon_path = icon_path\n",
    "        self.color = color\n",
    "        self.text = text\n",
    "        self.bg_color = self.color if(bg_color == None) else bg_color\n",
    "        self.alpha  = alpha\n",
    "\n",
    "    def overlay_green_screen(self):\n",
    "        # Create a green screen of the same size as the frame\n",
    "        screen = np.full(self.frame.shape, self.bg_color, dtype=np.uint8)\n",
    "        alpha = self.alpha\n",
    "        self.frame[:,:] = cv2.addWeighted(self.frame, 1 - alpha, screen, alpha, 0)\n",
    "\n",
    "    def display(self) -> None:\n",
    "        self.overlay_green_screen()\n",
    "        ImageUtils.overlay_icon(image=self.frame, \n",
    "                                icon_path=self.icon_path, \n",
    "                                color=self.color, \n",
    "                                icon_size=200, \n",
    "                                point=(self.frame.shape[1] // 2, self.frame.shape[0] // 2))\n",
    "        #draw text that says Press any key to unlock\n",
    "        font_weight=2\n",
    "        font_size=1.2\n",
    "        text = self.text\n",
    "        text_size, _ = cv.getTextSize(text, cv.FONT_HERSHEY_DUPLEX, font_size, font_weight)\n",
    "        text_width, text_height = text_size\n",
    "        text_x = self.frame.shape[1] // 2 - text_width // 2\n",
    "        text_y = self.frame.shape[0] // 2 + text_height + 150\n",
    "        cv.putText(self.frame, text, (text_x, text_y), cv.FONT_HERSHEY_DUPLEX, font_size, self.color, font_weight, lineType = cv2.LINE_AA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "class LockAuthenticationScreen(IconAuthenticationScreen):\n",
    "    def __init__(self, frame: np.ndarray) -> None:\n",
    "        super().__init__(frame, \"./assets/lock.png\", (255, 255, 255), \"PRESS A KEY TO START FACE RECOGNITION\", bg_color=(0, 0, 0), alpha=0.4)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AccessGrantedAuthenticationScreen(IconAuthenticationScreen):\n",
    "    def __init__(self, frame: np.ndarray) -> None:\n",
    "        super().__init__(frame, \"./assets/success.png\", (0, 255, 0), \"ACCESS GRANTED\", bg_color=(0, 255, 0), alpha = 0.15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AccessDeniedAuthenticationScreen(IconAuthenticationScreen):\n",
    "    def __init__(self, frame: np.ndarray) -> None:\n",
    "        super().__init__(frame, \"./assets/danger.png\", (0, 0, 255), \"ACCESS DENIED\", bg_color=(0, 0, 255), alpha = 0.15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mediapipe import solutions\n",
    "from mediapipe.framework.formats import landmark_pb2\n",
    "\n",
    "class FaceRecognizerAuthenticationScreen(AuthenticationScreen):\n",
    "    def __init__(self, frame: np.ndarray ) -> None:\n",
    "        self.frame = frame\n",
    "\n",
    "    def display(self) -> None:\n",
    "        self.draw_landmarks()\n",
    "        self.draw_processing_text()\n",
    "    \n",
    "    def draw_processing_text(self):\n",
    "        font_weight=2\n",
    "        font_size=1.2\n",
    "        text = \"PROCESSING FACE\"\n",
    "        text_size, _ = cv.getTextSize(text, cv.FONT_HERSHEY_DUPLEX, font_size, font_weight)\n",
    "        text_width, text_height = text_size\n",
    "        text_x = self.frame.shape[1] // 2 - text_width // 2\n",
    "        text_y = 300 \n",
    "        cv.putText(self.frame, text, (text_x, text_y), cv.FONT_HERSHEY_DUPLEX, font_size, (255, 255, 255), font_weight, lineType = cv2.LINE_AA)\n",
    "\n",
    "\n",
    "    def draw_landmarks(self):\n",
    "        base_options = python.BaseOptions(model_asset_path='./face_landmarker.task')\n",
    "        options = vision.FaceLandmarkerOptions(base_options=base_options,\n",
    "                                            output_face_blendshapes=True,\n",
    "                                            output_facial_transformation_matrixes=True)\n",
    "        detector = vision.FaceLandmarker.create_from_options(options)\n",
    "        mp_image = mp.Image(image_format=mp.ImageFormat.SRGB, data=self.frame)\n",
    "        detection_result = detector.detect(mp_image)\n",
    "        self.frame[::] = self.draw_landmarks_on_image(self.frame, detection_result)\n",
    "    \n",
    "    def draw_landmarks_on_image(self, rgb_image, detection_result):\n",
    "        face_landmarks_list = detection_result.face_landmarks\n",
    "        annotated_image = np.copy(rgb_image)\n",
    "\n",
    "        # Loop through the detected faces to visualize.\n",
    "        for idx in range(len(face_landmarks_list)):\n",
    "            face_landmarks = face_landmarks_list[idx]\n",
    "\n",
    "            # Draw the face landmarks.\n",
    "            face_landmarks_proto = landmark_pb2.NormalizedLandmarkList()\n",
    "            face_landmarks_proto.landmark.extend([\n",
    "            landmark_pb2.NormalizedLandmark(x=landmark.x, y=landmark.y, z=landmark.z) for landmark in face_landmarks\n",
    "            ])\n",
    "\n",
    "            solutions.drawing_utils.draw_landmarks(\n",
    "                image=annotated_image,\n",
    "                landmark_list=face_landmarks_proto,\n",
    "                connections=mp.solutions.face_mesh.FACEMESH_TESSELATION,\n",
    "                landmark_drawing_spec=None,\n",
    "                connection_drawing_spec=mp.solutions.drawing_styles\n",
    "                .get_default_face_mesh_tesselation_style())\n",
    "            solutions.drawing_utils.draw_landmarks(\n",
    "                image=annotated_image,\n",
    "                landmark_list=face_landmarks_proto,\n",
    "                connections=mp.solutions.face_mesh.FACEMESH_CONTOURS,\n",
    "                landmark_drawing_spec=None,\n",
    "                connection_drawing_spec=mp.solutions.drawing_styles\n",
    "                .get_default_face_mesh_contours_style())\n",
    "            solutions.drawing_utils.draw_landmarks(\n",
    "                image=annotated_image,\n",
    "                landmark_list=face_landmarks_proto,\n",
    "                connections=mp.solutions.face_mesh.FACEMESH_IRISES,\n",
    "                landmark_drawing_spec=None,\n",
    "                connection_drawing_spec=mp.solutions.drawing_styles\n",
    "                .get_default_face_mesh_iris_connections_style())\n",
    "\n",
    "        return annotated_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class InputManager:\n",
    "    @staticmethod\n",
    "    def is_space_pressed() -> bool:\n",
    "        return cv.waitKey(1) & 0xFF == ord(' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import threading\n",
    "\n",
    "class MockFaceComparator(FaceComparator):\n",
    "    def compare(self, first_face : FaceDetectorResult, second_face : FaceDetectorResult, ) -> FaceComparatorResult:\n",
    "        return FaceComparatorResult(1)\n",
    "\n",
    "class FaceAuthorizator:\n",
    "    def __init__(self, face_detector: FaceDetector, face_comparator: FaceComparator, base_path: str, threshold: float):\n",
    "        self.is_authorizated = False\n",
    "        self.finished_recognition = False\n",
    "        self.face_comparator = face_comparator\n",
    "        self.face_detector = face_detector\n",
    "        self.base_path = base_path\n",
    "        self.threshold = threshold\n",
    "    \n",
    "    def load_person(self, path):\n",
    "        return cv.imread(self.base_path + path)\n",
    "    \n",
    "    def list_image_paths_in_base_path(self):\n",
    "        return [f for f in os.listdir(self.base_path) if os.path.isfile(os.path.join(self.base_path, f))]\n",
    "\n",
    "    def set_authorizated(self, frame):\n",
    "        detection_results = []\n",
    "        for image in self.list_image_paths_in_base_path():\n",
    "            try:\n",
    "                detected_person = self.face_detector.detect(frame)\n",
    "                base_person = self.face_detector.detect(self.load_person(image))\n",
    "                if(len(base_person) < 1 or len(detected_person) < 1):\n",
    "                    self.is_authorizated = False\n",
    "                    self.finished_recognition=True\n",
    "                    break\n",
    "                detection_results.append(self.face_comparator.compare(detected_person[0], base_person[0]).similarity)\n",
    "            except:\n",
    "                continue\n",
    "        \n",
    "        if(len(detection_results) > 0):\n",
    "            detection_mean = sum(detection_results) / len(detection_results)\n",
    "            self.is_authorizated = True if detection_mean < self.threshold else False\n",
    "        else:\n",
    "            self.is_authorizated = False\n",
    "        self.finished_recognition=True\n",
    "    \n",
    "    def start_authorization_thread(self, frame):\n",
    "        timer = threading.Timer(0, lambda  : self.set_authorizated(frame))\n",
    "        timer.start()\n",
    "\n",
    "    def is_access_denied(self) -> bool:\n",
    "        return not self.is_authorizated and self.finished_recognition\n",
    "    \n",
    "    def is_access_granted(self) -> bool:\n",
    "        return self.is_authorizated and self.finished_recognition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## STATE MACHINE CREATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1701875214.917970       1 gl_context.cc:344] GL version: 2.1 (2.1 ATI-4.12.7), renderer: AMD Radeon Pro 5300M OpenGL Engine\n",
      "W0000 00:00:1701875214.921636       1 face_landmarker_graph.cc:174] Sets FaceBlendshapesGraph acceleration to xnnpack by default.\n",
      "I0000 00:00:1701875215.122630       1 gl_context.cc:344] GL version: 2.1 (2.1 ATI-4.12.7), renderer: AMD Radeon Pro 5300M OpenGL Engine\n",
      "W0000 00:00:1701875215.123348       1 face_landmarker_graph.cc:174] Sets FaceBlendshapesGraph acceleration to xnnpack by default.\n",
      "I0000 00:00:1701875215.355528       1 gl_context.cc:344] GL version: 2.1 (2.1 ATI-4.12.7), renderer: AMD Radeon Pro 5300M OpenGL Engine\n",
      "W0000 00:00:1701875215.356362       1 face_landmarker_graph.cc:174] Sets FaceBlendshapesGraph acceleration to xnnpack by default.\n",
      "I0000 00:00:1701875215.653890       1 gl_context.cc:344] GL version: 2.1 (2.1 ATI-4.12.7), renderer: AMD Radeon Pro 5300M OpenGL Engine\n",
      "W0000 00:00:1701875215.654449       1 face_landmarker_graph.cc:174] Sets FaceBlendshapesGraph acceleration to xnnpack by default.\n",
      "I0000 00:00:1701875215.965255       1 gl_context.cc:344] GL version: 2.1 (2.1 ATI-4.12.7), renderer: AMD Radeon Pro 5300M OpenGL Engine\n",
      "W0000 00:00:1701875215.965900       1 face_landmarker_graph.cc:174] Sets FaceBlendshapesGraph acceleration to xnnpack by default.\n",
      "I0000 00:00:1701875216.183907       1 gl_context.cc:344] GL version: 2.1 (2.1 ATI-4.12.7), renderer: AMD Radeon Pro 5300M OpenGL Engine\n",
      "W0000 00:00:1701875216.184540       1 face_landmarker_graph.cc:174] Sets FaceBlendshapesGraph acceleration to xnnpack by default.\n",
      "I0000 00:00:1701875216.452137       1 gl_context.cc:344] GL version: 2.1 (2.1 ATI-4.12.7), renderer: AMD Radeon Pro 5300M OpenGL Engine\n",
      "W0000 00:00:1701875216.452758       1 face_landmarker_graph.cc:174] Sets FaceBlendshapesGraph acceleration to xnnpack by default.\n",
      "I0000 00:00:1701875216.650464       1 gl_context.cc:344] GL version: 2.1 (2.1 ATI-4.12.7), renderer: AMD Radeon Pro 5300M OpenGL Engine\n",
      "W0000 00:00:1701875216.651018       1 face_landmarker_graph.cc:174] Sets FaceBlendshapesGraph acceleration to xnnpack by default.\n",
      "I0000 00:00:1701875216.917880       1 gl_context.cc:344] GL version: 2.1 (2.1 ATI-4.12.7), renderer: AMD Radeon Pro 5300M OpenGL Engine\n",
      "W0000 00:00:1701875216.918440       1 face_landmarker_graph.cc:174] Sets FaceBlendshapesGraph acceleration to xnnpack by default.\n",
      "I0000 00:00:1701875217.122190       1 gl_context.cc:344] GL version: 2.1 (2.1 ATI-4.12.7), renderer: AMD Radeon Pro 5300M OpenGL Engine\n",
      "W0000 00:00:1701875217.122797       1 face_landmarker_graph.cc:174] Sets FaceBlendshapesGraph acceleration to xnnpack by default.\n",
      "I0000 00:00:1701875217.385161       1 gl_context.cc:344] GL version: 2.1 (2.1 ATI-4.12.7), renderer: AMD Radeon Pro 5300M OpenGL Engine\n",
      "W0000 00:00:1701875217.385840       1 face_landmarker_graph.cc:174] Sets FaceBlendshapesGraph acceleration to xnnpack by default.\n",
      "I0000 00:00:1701875217.652826       1 gl_context.cc:344] GL version: 2.1 (2.1 ATI-4.12.7), renderer: AMD Radeon Pro 5300M OpenGL Engine\n",
      "W0000 00:00:1701875217.653479       1 face_landmarker_graph.cc:174] Sets FaceBlendshapesGraph acceleration to xnnpack by default.\n",
      "I0000 00:00:1701875217.851842       1 gl_context.cc:344] GL version: 2.1 (2.1 ATI-4.12.7), renderer: AMD Radeon Pro 5300M OpenGL Engine\n",
      "W0000 00:00:1701875217.853506       1 face_landmarker_graph.cc:174] Sets FaceBlendshapesGraph acceleration to xnnpack by default.\n",
      "I0000 00:00:1701875218.052083       1 gl_context.cc:344] GL version: 2.1 (2.1 ATI-4.12.7), renderer: AMD Radeon Pro 5300M OpenGL Engine\n",
      "W0000 00:00:1701875218.052716       1 face_landmarker_graph.cc:174] Sets FaceBlendshapesGraph acceleration to xnnpack by default.\n",
      "I0000 00:00:1701875218.412493       1 gl_context.cc:344] GL version: 2.1 (2.1 ATI-4.12.7), renderer: AMD Radeon Pro 5300M OpenGL Engine\n",
      "W0000 00:00:1701875218.413229       1 face_landmarker_graph.cc:174] Sets FaceBlendshapesGraph acceleration to xnnpack by default.\n",
      "I0000 00:00:1701875218.655629       1 gl_context.cc:344] GL version: 2.1 (2.1 ATI-4.12.7), renderer: AMD Radeon Pro 5300M OpenGL Engine\n",
      "W0000 00:00:1701875218.656213       1 face_landmarker_graph.cc:174] Sets FaceBlendshapesGraph acceleration to xnnpack by default.\n",
      "I0000 00:00:1701875218.894157       1 gl_context.cc:344] GL version: 2.1 (2.1 ATI-4.12.7), renderer: AMD Radeon Pro 5300M OpenGL Engine\n",
      "W0000 00:00:1701875218.894779       1 face_landmarker_graph.cc:174] Sets FaceBlendshapesGraph acceleration to xnnpack by default.\n",
      "I0000 00:00:1701875219.118851       1 gl_context.cc:344] GL version: 2.1 (2.1 ATI-4.12.7), renderer: AMD Radeon Pro 5300M OpenGL Engine\n",
      "W0000 00:00:1701875219.119460       1 face_landmarker_graph.cc:174] Sets FaceBlendshapesGraph acceleration to xnnpack by default.\n",
      "I0000 00:00:1701875219.356836       1 gl_context.cc:344] GL version: 2.1 (2.1 ATI-4.12.7), renderer: AMD Radeon Pro 5300M OpenGL Engine\n",
      "W0000 00:00:1701875219.357568       1 face_landmarker_graph.cc:174] Sets FaceBlendshapesGraph acceleration to xnnpack by default.\n",
      "I0000 00:00:1701875219.689954       1 gl_context.cc:344] GL version: 2.1 (2.1 ATI-4.12.7), renderer: AMD Radeon Pro 5300M OpenGL Engine\n",
      "W0000 00:00:1701875219.690765       1 face_landmarker_graph.cc:174] Sets FaceBlendshapesGraph acceleration to xnnpack by default.\n",
      "I0000 00:00:1701875219.949853       1 gl_context.cc:344] GL version: 2.1 (2.1 ATI-4.12.7), renderer: AMD Radeon Pro 5300M OpenGL Engine\n",
      "W0000 00:00:1701875219.950299       1 face_landmarker_graph.cc:174] Sets FaceBlendshapesGraph acceleration to xnnpack by default.\n",
      "I0000 00:00:1701875220.085172       1 gl_context.cc:344] GL version: 2.1 (2.1 ATI-4.12.7), renderer: AMD Radeon Pro 5300M OpenGL Engine\n",
      "W0000 00:00:1701875220.085701       1 face_landmarker_graph.cc:174] Sets FaceBlendshapesGraph acceleration to xnnpack by default.\n",
      "I0000 00:00:1701875220.288973       1 gl_context.cc:344] GL version: 2.1 (2.1 ATI-4.12.7), renderer: AMD Radeon Pro 5300M OpenGL Engine\n",
      "W0000 00:00:1701875220.289710       1 face_landmarker_graph.cc:174] Sets FaceBlendshapesGraph acceleration to xnnpack by default.\n",
      "I0000 00:00:1701875220.552377       1 gl_context.cc:344] GL version: 2.1 (2.1 ATI-4.12.7), renderer: AMD Radeon Pro 5300M OpenGL Engine\n",
      "W0000 00:00:1701875220.553213       1 face_landmarker_graph.cc:174] Sets FaceBlendshapesGraph acceleration to xnnpack by default.\n",
      "I0000 00:00:1701875220.867441       1 gl_context.cc:344] GL version: 2.1 (2.1 ATI-4.12.7), renderer: AMD Radeon Pro 5300M OpenGL Engine\n",
      "W0000 00:00:1701875220.868110       1 face_landmarker_graph.cc:174] Sets FaceBlendshapesGraph acceleration to xnnpack by default.\n",
      "I0000 00:00:1701875221.151504       1 gl_context.cc:344] GL version: 2.1 (2.1 ATI-4.12.7), renderer: AMD Radeon Pro 5300M OpenGL Engine\n",
      "W0000 00:00:1701875221.152159       1 face_landmarker_graph.cc:174] Sets FaceBlendshapesGraph acceleration to xnnpack by default.\n",
      "I0000 00:00:1701875221.388308       1 gl_context.cc:344] GL version: 2.1 (2.1 ATI-4.12.7), renderer: AMD Radeon Pro 5300M OpenGL Engine\n",
      "W0000 00:00:1701875221.388946       1 face_landmarker_graph.cc:174] Sets FaceBlendshapesGraph acceleration to xnnpack by default.\n",
      "I0000 00:00:1701875221.651483       1 gl_context.cc:344] GL version: 2.1 (2.1 ATI-4.12.7), renderer: AMD Radeon Pro 5300M OpenGL Engine\n",
      "W0000 00:00:1701875221.652185       1 face_landmarker_graph.cc:174] Sets FaceBlendshapesGraph acceleration to xnnpack by default.\n",
      "I0000 00:00:1701875221.885719       1 gl_context.cc:344] GL version: 2.1 (2.1 ATI-4.12.7), renderer: AMD Radeon Pro 5300M OpenGL Engine\n",
      "W0000 00:00:1701875221.886514       1 face_landmarker_graph.cc:174] Sets FaceBlendshapesGraph acceleration to xnnpack by default.\n",
      "I0000 00:00:1701875222.185981       1 gl_context.cc:344] GL version: 2.1 (2.1 ATI-4.12.7), renderer: AMD Radeon Pro 5300M OpenGL Engine\n",
      "W0000 00:00:1701875222.186690       1 face_landmarker_graph.cc:174] Sets FaceBlendshapesGraph acceleration to xnnpack by default.\n",
      "I0000 00:00:1701875222.449309       1 gl_context.cc:344] GL version: 2.1 (2.1 ATI-4.12.7), renderer: AMD Radeon Pro 5300M OpenGL Engine\n",
      "W0000 00:00:1701875222.450213       1 face_landmarker_graph.cc:174] Sets FaceBlendshapesGraph acceleration to xnnpack by default.\n",
      "I0000 00:00:1701875222.718488       1 gl_context.cc:344] GL version: 2.1 (2.1 ATI-4.12.7), renderer: AMD Radeon Pro 5300M OpenGL Engine\n",
      "W0000 00:00:1701875222.721174       1 face_landmarker_graph.cc:174] Sets FaceBlendshapesGraph acceleration to xnnpack by default.\n",
      "I0000 00:00:1701875222.980709       1 gl_context.cc:344] GL version: 2.1 (2.1 ATI-4.12.7), renderer: AMD Radeon Pro 5300M OpenGL Engine\n",
      "W0000 00:00:1701875222.981144       1 face_landmarker_graph.cc:174] Sets FaceBlendshapesGraph acceleration to xnnpack by default.\n",
      "I0000 00:00:1701875223.186304       1 gl_context.cc:344] GL version: 2.1 (2.1 ATI-4.12.7), renderer: AMD Radeon Pro 5300M OpenGL Engine\n",
      "W0000 00:00:1701875223.186955       1 face_landmarker_graph.cc:174] Sets FaceBlendshapesGraph acceleration to xnnpack by default.\n",
      "I0000 00:00:1701875223.496551       1 gl_context.cc:344] GL version: 2.1 (2.1 ATI-4.12.7), renderer: AMD Radeon Pro 5300M OpenGL Engine\n",
      "W0000 00:00:1701875223.497147       1 face_landmarker_graph.cc:174] Sets FaceBlendshapesGraph acceleration to xnnpack by default.\n",
      "I0000 00:00:1701875223.748314       1 gl_context.cc:344] GL version: 2.1 (2.1 ATI-4.12.7), renderer: AMD Radeon Pro 5300M OpenGL Engine\n",
      "W0000 00:00:1701875223.748965       1 face_landmarker_graph.cc:174] Sets FaceBlendshapesGraph acceleration to xnnpack by default.\n",
      "I0000 00:00:1701875223.984810       1 gl_context.cc:344] GL version: 2.1 (2.1 ATI-4.12.7), renderer: AMD Radeon Pro 5300M OpenGL Engine\n",
      "W0000 00:00:1701875223.985292       1 face_landmarker_graph.cc:174] Sets FaceBlendshapesGraph acceleration to xnnpack by default.\n",
      "I0000 00:00:1701875224.218343       1 gl_context.cc:344] GL version: 2.1 (2.1 ATI-4.12.7), renderer: AMD Radeon Pro 5300M OpenGL Engine\n",
      "W0000 00:00:1701875224.218880       1 face_landmarker_graph.cc:174] Sets FaceBlendshapesGraph acceleration to xnnpack by default.\n",
      "I0000 00:00:1701875224.451763       1 gl_context.cc:344] GL version: 2.1 (2.1 ATI-4.12.7), renderer: AMD Radeon Pro 5300M OpenGL Engine\n",
      "W0000 00:00:1701875224.452263       1 face_landmarker_graph.cc:174] Sets FaceBlendshapesGraph acceleration to xnnpack by default.\n",
      "I0000 00:00:1701875224.681288       1 gl_context.cc:344] GL version: 2.1 (2.1 ATI-4.12.7), renderer: AMD Radeon Pro 5300M OpenGL Engine\n",
      "W0000 00:00:1701875224.682047       1 face_landmarker_graph.cc:174] Sets FaceBlendshapesGraph acceleration to xnnpack by default.\n",
      "I0000 00:00:1701875224.915896       1 gl_context.cc:344] GL version: 2.1 (2.1 ATI-4.12.7), renderer: AMD Radeon Pro 5300M OpenGL Engine\n",
      "W0000 00:00:1701875224.916485       1 face_landmarker_graph.cc:174] Sets FaceBlendshapesGraph acceleration to xnnpack by default.\n",
      "I0000 00:00:1701875225.148806       1 gl_context.cc:344] GL version: 2.1 (2.1 ATI-4.12.7), renderer: AMD Radeon Pro 5300M OpenGL Engine\n",
      "W0000 00:00:1701875225.149377       1 face_landmarker_graph.cc:174] Sets FaceBlendshapesGraph acceleration to xnnpack by default.\n",
      "I0000 00:00:1701875225.347474       1 gl_context.cc:344] GL version: 2.1 (2.1 ATI-4.12.7), renderer: AMD Radeon Pro 5300M OpenGL Engine\n",
      "W0000 00:00:1701875225.348124       1 face_landmarker_graph.cc:174] Sets FaceBlendshapesGraph acceleration to xnnpack by default.\n",
      "I0000 00:00:1701875225.546830       1 gl_context.cc:344] GL version: 2.1 (2.1 ATI-4.12.7), renderer: AMD Radeon Pro 5300M OpenGL Engine\n",
      "W0000 00:00:1701875225.547336       1 face_landmarker_graph.cc:174] Sets FaceBlendshapesGraph acceleration to xnnpack by default.\n",
      "I0000 00:00:1701875225.714364       1 gl_context.cc:344] GL version: 2.1 (2.1 ATI-4.12.7), renderer: AMD Radeon Pro 5300M OpenGL Engine\n",
      "W0000 00:00:1701875225.714983       1 face_landmarker_graph.cc:174] Sets FaceBlendshapesGraph acceleration to xnnpack by default.\n",
      "I0000 00:00:1701875225.879591       1 gl_context.cc:344] GL version: 2.1 (2.1 ATI-4.12.7), renderer: AMD Radeon Pro 5300M OpenGL Engine\n",
      "W0000 00:00:1701875225.880060       1 face_landmarker_graph.cc:174] Sets FaceBlendshapesGraph acceleration to xnnpack by default.\n",
      "I0000 00:00:1701875226.046674       1 gl_context.cc:344] GL version: 2.1 (2.1 ATI-4.12.7), renderer: AMD Radeon Pro 5300M OpenGL Engine\n",
      "W0000 00:00:1701875226.047146       1 face_landmarker_graph.cc:174] Sets FaceBlendshapesGraph acceleration to xnnpack by default.\n",
      "I0000 00:00:1701875226.248112       1 gl_context.cc:344] GL version: 2.1 (2.1 ATI-4.12.7), renderer: AMD Radeon Pro 5300M OpenGL Engine\n",
      "W0000 00:00:1701875226.248529       1 face_landmarker_graph.cc:174] Sets FaceBlendshapesGraph acceleration to xnnpack by default.\n",
      "I0000 00:00:1701875226.479825       1 gl_context.cc:344] GL version: 2.1 (2.1 ATI-4.12.7), renderer: AMD Radeon Pro 5300M OpenGL Engine\n",
      "W0000 00:00:1701875226.480273       1 face_landmarker_graph.cc:174] Sets FaceBlendshapesGraph acceleration to xnnpack by default.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'verified': True, 'distance': 0.38761290013832905, 'threshold': 0.4, 'model': 'VGG-Face', 'detector_backend': 'opencv', 'similarity_metric': 'cosine', 'facial_areas': {'img1': {'x': 0, 'y': 0, 'w': 345, 'h': 234}, 'img2': {'x': 0, 'y': 0, 'w': 537, 'h': 416}}, 'time': 1.52}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1701875226.691701       1 gl_context.cc:344] GL version: 2.1 (2.1 ATI-4.12.7), renderer: AMD Radeon Pro 5300M OpenGL Engine\n",
      "W0000 00:00:1701875226.692277       1 face_landmarker_graph.cc:174] Sets FaceBlendshapesGraph acceleration to xnnpack by default.\n",
      "I0000 00:00:1701875226.964765       1 gl_context.cc:344] GL version: 2.1 (2.1 ATI-4.12.7), renderer: AMD Radeon Pro 5300M OpenGL Engine\n",
      "W0000 00:00:1701875226.965677       1 face_landmarker_graph.cc:174] Sets FaceBlendshapesGraph acceleration to xnnpack by default.\n",
      "I0000 00:00:1701875227.780748       1 gl_context.cc:344] GL version: 2.1 (2.1 ATI-4.12.7), renderer: AMD Radeon Pro 5300M OpenGL Engine\n",
      "W0000 00:00:1701875227.781374       1 face_landmarker_graph.cc:174] Sets FaceBlendshapesGraph acceleration to xnnpack by default.\n",
      "I0000 00:00:1701875228.053463       1 gl_context.cc:344] GL version: 2.1 (2.1 ATI-4.12.7), renderer: AMD Radeon Pro 5300M OpenGL Engine\n",
      "W0000 00:00:1701875228.053913       1 face_landmarker_graph.cc:174] Sets FaceBlendshapesGraph acceleration to xnnpack by default.\n",
      "I0000 00:00:1701875228.280510       1 gl_context.cc:344] GL version: 2.1 (2.1 ATI-4.12.7), renderer: AMD Radeon Pro 5300M OpenGL Engine\n",
      "W0000 00:00:1701875228.280965       1 face_landmarker_graph.cc:174] Sets FaceBlendshapesGraph acceleration to xnnpack by default.\n",
      "I0000 00:00:1701875228.551341       1 gl_context.cc:344] GL version: 2.1 (2.1 ATI-4.12.7), renderer: AMD Radeon Pro 5300M OpenGL Engine\n",
      "W0000 00:00:1701875228.552552       1 face_landmarker_graph.cc:174] Sets FaceBlendshapesGraph acceleration to xnnpack by default.\n",
      "I0000 00:00:1701875228.783177       1 gl_context.cc:344] GL version: 2.1 (2.1 ATI-4.12.7), renderer: AMD Radeon Pro 5300M OpenGL Engine\n",
      "W0000 00:00:1701875228.783974       1 face_landmarker_graph.cc:174] Sets FaceBlendshapesGraph acceleration to xnnpack by default.\n",
      "I0000 00:00:1701875229.080897       1 gl_context.cc:344] GL version: 2.1 (2.1 ATI-4.12.7), renderer: AMD Radeon Pro 5300M OpenGL Engine\n",
      "W0000 00:00:1701875229.081651       1 face_landmarker_graph.cc:174] Sets FaceBlendshapesGraph acceleration to xnnpack by default.\n",
      "I0000 00:00:1701875229.312923       1 gl_context.cc:344] GL version: 2.1 (2.1 ATI-4.12.7), renderer: AMD Radeon Pro 5300M OpenGL Engine\n",
      "W0000 00:00:1701875229.313677       1 face_landmarker_graph.cc:174] Sets FaceBlendshapesGraph acceleration to xnnpack by default.\n",
      "I0000 00:00:1701875229.582301       1 gl_context.cc:344] GL version: 2.1 (2.1 ATI-4.12.7), renderer: AMD Radeon Pro 5300M OpenGL Engine\n",
      "W0000 00:00:1701875229.583045       1 face_landmarker_graph.cc:174] Sets FaceBlendshapesGraph acceleration to xnnpack by default.\n",
      "I0000 00:00:1701875229.744622       1 gl_context.cc:344] GL version: 2.1 (2.1 ATI-4.12.7), renderer: AMD Radeon Pro 5300M OpenGL Engine\n",
      "W0000 00:00:1701875229.745058       1 face_landmarker_graph.cc:174] Sets FaceBlendshapesGraph acceleration to xnnpack by default.\n",
      "I0000 00:00:1701875229.910825       1 gl_context.cc:344] GL version: 2.1 (2.1 ATI-4.12.7), renderer: AMD Radeon Pro 5300M OpenGL Engine\n",
      "W0000 00:00:1701875229.911259       1 face_landmarker_graph.cc:174] Sets FaceBlendshapesGraph acceleration to xnnpack by default.\n",
      "I0000 00:00:1701875230.189473       1 gl_context.cc:344] GL version: 2.1 (2.1 ATI-4.12.7), renderer: AMD Radeon Pro 5300M OpenGL Engine\n",
      "W0000 00:00:1701875230.190449       1 face_landmarker_graph.cc:174] Sets FaceBlendshapesGraph acceleration to xnnpack by default.\n",
      "I0000 00:00:1701875230.491023       1 gl_context.cc:344] GL version: 2.1 (2.1 ATI-4.12.7), renderer: AMD Radeon Pro 5300M OpenGL Engine\n",
      "W0000 00:00:1701875230.492621       1 face_landmarker_graph.cc:174] Sets FaceBlendshapesGraph acceleration to xnnpack by default.\n",
      "I0000 00:00:1701875230.754913       1 gl_context.cc:344] GL version: 2.1 (2.1 ATI-4.12.7), renderer: AMD Radeon Pro 5300M OpenGL Engine\n",
      "W0000 00:00:1701875230.755529       1 face_landmarker_graph.cc:174] Sets FaceBlendshapesGraph acceleration to xnnpack by default.\n",
      "I0000 00:00:1701875231.016165       1 gl_context.cc:344] GL version: 2.1 (2.1 ATI-4.12.7), renderer: AMD Radeon Pro 5300M OpenGL Engine\n",
      "W0000 00:00:1701875231.016928       1 face_landmarker_graph.cc:174] Sets FaceBlendshapesGraph acceleration to xnnpack by default.\n",
      "I0000 00:00:1701875231.279000       1 gl_context.cc:344] GL version: 2.1 (2.1 ATI-4.12.7), renderer: AMD Radeon Pro 5300M OpenGL Engine\n",
      "W0000 00:00:1701875231.279698       1 face_landmarker_graph.cc:174] Sets FaceBlendshapesGraph acceleration to xnnpack by default.\n",
      "I0000 00:00:1701875231.546118       1 gl_context.cc:344] GL version: 2.1 (2.1 ATI-4.12.7), renderer: AMD Radeon Pro 5300M OpenGL Engine\n",
      "W0000 00:00:1701875231.546885       1 face_landmarker_graph.cc:174] Sets FaceBlendshapesGraph acceleration to xnnpack by default.\n",
      "I0000 00:00:1701875231.812494       1 gl_context.cc:344] GL version: 2.1 (2.1 ATI-4.12.7), renderer: AMD Radeon Pro 5300M OpenGL Engine\n",
      "W0000 00:00:1701875231.813200       1 face_landmarker_graph.cc:174] Sets FaceBlendshapesGraph acceleration to xnnpack by default.\n",
      "I0000 00:00:1701875232.045266       1 gl_context.cc:344] GL version: 2.1 (2.1 ATI-4.12.7), renderer: AMD Radeon Pro 5300M OpenGL Engine\n",
      "W0000 00:00:1701875232.045743       1 face_landmarker_graph.cc:174] Sets FaceBlendshapesGraph acceleration to xnnpack by default.\n",
      "I0000 00:00:1701875232.344117       1 gl_context.cc:344] GL version: 2.1 (2.1 ATI-4.12.7), renderer: AMD Radeon Pro 5300M OpenGL Engine\n",
      "W0000 00:00:1701875232.344745       1 face_landmarker_graph.cc:174] Sets FaceBlendshapesGraph acceleration to xnnpack by default.\n",
      "I0000 00:00:1701875232.514855       1 gl_context.cc:344] GL version: 2.1 (2.1 ATI-4.12.7), renderer: AMD Radeon Pro 5300M OpenGL Engine\n",
      "W0000 00:00:1701875232.515664       1 face_landmarker_graph.cc:174] Sets FaceBlendshapesGraph acceleration to xnnpack by default.\n",
      "I0000 00:00:1701875232.710879       1 gl_context.cc:344] GL version: 2.1 (2.1 ATI-4.12.7), renderer: AMD Radeon Pro 5300M OpenGL Engine\n",
      "W0000 00:00:1701875232.711393       1 face_landmarker_graph.cc:174] Sets FaceBlendshapesGraph acceleration to xnnpack by default.\n",
      "I0000 00:00:1701875232.910084       1 gl_context.cc:344] GL version: 2.1 (2.1 ATI-4.12.7), renderer: AMD Radeon Pro 5300M OpenGL Engine\n",
      "W0000 00:00:1701875232.910570       1 face_landmarker_graph.cc:174] Sets FaceBlendshapesGraph acceleration to xnnpack by default.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'verified': False, 'distance': 0.4588278686222048, 'threshold': 0.4, 'model': 'VGG-Face', 'detector_backend': 'opencv', 'similarity_metric': 'cosine', 'facial_areas': {'img1': {'x': 0, 'y': 0, 'w': 345, 'h': 234}, 'img2': {'x': 0, 'y': 0, 'w': 664, 'h': 571}}, 'time': 0.83}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1701875233.108784       1 gl_context.cc:344] GL version: 2.1 (2.1 ATI-4.12.7), renderer: AMD Radeon Pro 5300M OpenGL Engine\n",
      "W0000 00:00:1701875233.109207       1 face_landmarker_graph.cc:174] Sets FaceBlendshapesGraph acceleration to xnnpack by default.\n",
      "I0000 00:00:1701875233.353953       1 gl_context.cc:344] GL version: 2.1 (2.1 ATI-4.12.7), renderer: AMD Radeon Pro 5300M OpenGL Engine\n",
      "W0000 00:00:1701875233.354671       1 face_landmarker_graph.cc:174] Sets FaceBlendshapesGraph acceleration to xnnpack by default.\n",
      "I0000 00:00:1701875233.732107       1 gl_context.cc:344] GL version: 2.1 (2.1 ATI-4.12.7), renderer: AMD Radeon Pro 5300M OpenGL Engine\n",
      "W0000 00:00:1701875233.733172       1 face_landmarker_graph.cc:174] Sets FaceBlendshapesGraph acceleration to xnnpack by default.\n",
      "I0000 00:00:1701875233.981115       1 gl_context.cc:344] GL version: 2.1 (2.1 ATI-4.12.7), renderer: AMD Radeon Pro 5300M OpenGL Engine\n",
      "W0000 00:00:1701875233.981719       1 face_landmarker_graph.cc:174] Sets FaceBlendshapesGraph acceleration to xnnpack by default.\n",
      "I0000 00:00:1701875234.211091       1 gl_context.cc:344] GL version: 2.1 (2.1 ATI-4.12.7), renderer: AMD Radeon Pro 5300M OpenGL Engine\n",
      "W0000 00:00:1701875234.211868       1 face_landmarker_graph.cc:174] Sets FaceBlendshapesGraph acceleration to xnnpack by default.\n",
      "I0000 00:00:1701875234.481093       1 gl_context.cc:344] GL version: 2.1 (2.1 ATI-4.12.7), renderer: AMD Radeon Pro 5300M OpenGL Engine\n",
      "W0000 00:00:1701875234.481728       1 face_landmarker_graph.cc:174] Sets FaceBlendshapesGraph acceleration to xnnpack by default.\n",
      "I0000 00:00:1701875234.713053       1 gl_context.cc:344] GL version: 2.1 (2.1 ATI-4.12.7), renderer: AMD Radeon Pro 5300M OpenGL Engine\n",
      "W0000 00:00:1701875234.713690       1 face_landmarker_graph.cc:174] Sets FaceBlendshapesGraph acceleration to xnnpack by default.\n",
      "I0000 00:00:1701875234.946447       1 gl_context.cc:344] GL version: 2.1 (2.1 ATI-4.12.7), renderer: AMD Radeon Pro 5300M OpenGL Engine\n",
      "W0000 00:00:1701875234.947605       1 face_landmarker_graph.cc:174] Sets FaceBlendshapesGraph acceleration to xnnpack by default.\n",
      "I0000 00:00:1701875235.245177       1 gl_context.cc:344] GL version: 2.1 (2.1 ATI-4.12.7), renderer: AMD Radeon Pro 5300M OpenGL Engine\n",
      "W0000 00:00:1701875235.245920       1 face_landmarker_graph.cc:174] Sets FaceBlendshapesGraph acceleration to xnnpack by default.\n",
      "I0000 00:00:1701875235.544485       1 gl_context.cc:344] GL version: 2.1 (2.1 ATI-4.12.7), renderer: AMD Radeon Pro 5300M OpenGL Engine\n",
      "W0000 00:00:1701875235.545170       1 face_landmarker_graph.cc:174] Sets FaceBlendshapesGraph acceleration to xnnpack by default.\n",
      "I0000 00:00:1701875235.842467       1 gl_context.cc:344] GL version: 2.1 (2.1 ATI-4.12.7), renderer: AMD Radeon Pro 5300M OpenGL Engine\n",
      "W0000 00:00:1701875235.843238       1 face_landmarker_graph.cc:174] Sets FaceBlendshapesGraph acceleration to xnnpack by default.\n",
      "I0000 00:00:1701875236.010830       1 gl_context.cc:344] GL version: 2.1 (2.1 ATI-4.12.7), renderer: AMD Radeon Pro 5300M OpenGL Engine\n",
      "W0000 00:00:1701875236.011486       1 face_landmarker_graph.cc:174] Sets FaceBlendshapesGraph acceleration to xnnpack by default.\n",
      "I0000 00:00:1701875236.258860       1 gl_context.cc:344] GL version: 2.1 (2.1 ATI-4.12.7), renderer: AMD Radeon Pro 5300M OpenGL Engine\n",
      "W0000 00:00:1701875236.259699       1 face_landmarker_graph.cc:174] Sets FaceBlendshapesGraph acceleration to xnnpack by default.\n",
      "I0000 00:00:1701875236.580185       1 gl_context.cc:344] GL version: 2.1 (2.1 ATI-4.12.7), renderer: AMD Radeon Pro 5300M OpenGL Engine\n",
      "W0000 00:00:1701875236.580815       1 face_landmarker_graph.cc:174] Sets FaceBlendshapesGraph acceleration to xnnpack by default.\n",
      "I0000 00:00:1701875236.817977       1 gl_context.cc:344] GL version: 2.1 (2.1 ATI-4.12.7), renderer: AMD Radeon Pro 5300M OpenGL Engine\n",
      "W0000 00:00:1701875236.819416       1 face_landmarker_graph.cc:174] Sets FaceBlendshapesGraph acceleration to xnnpack by default.\n",
      "I0000 00:00:1701875237.144999       1 gl_context.cc:344] GL version: 2.1 (2.1 ATI-4.12.7), renderer: AMD Radeon Pro 5300M OpenGL Engine\n",
      "W0000 00:00:1701875237.145723       1 face_landmarker_graph.cc:174] Sets FaceBlendshapesGraph acceleration to xnnpack by default.\n",
      "I0000 00:00:1701875237.281619       1 gl_context.cc:344] GL version: 2.1 (2.1 ATI-4.12.7), renderer: AMD Radeon Pro 5300M OpenGL Engine\n",
      "W0000 00:00:1701875237.282965       1 face_landmarker_graph.cc:174] Sets FaceBlendshapesGraph acceleration to xnnpack by default.\n",
      "I0000 00:00:1701875237.546199       1 gl_context.cc:344] GL version: 2.1 (2.1 ATI-4.12.7), renderer: AMD Radeon Pro 5300M OpenGL Engine\n",
      "W0000 00:00:1701875237.546992       1 face_landmarker_graph.cc:174] Sets FaceBlendshapesGraph acceleration to xnnpack by default.\n",
      "I0000 00:00:1701875237.810245       1 gl_context.cc:344] GL version: 2.1 (2.1 ATI-4.12.7), renderer: AMD Radeon Pro 5300M OpenGL Engine\n",
      "W0000 00:00:1701875237.810971       1 face_landmarker_graph.cc:174] Sets FaceBlendshapesGraph acceleration to xnnpack by default.\n",
      "I0000 00:00:1701875238.080105       1 gl_context.cc:344] GL version: 2.1 (2.1 ATI-4.12.7), renderer: AMD Radeon Pro 5300M OpenGL Engine\n",
      "W0000 00:00:1701875238.080892       1 face_landmarker_graph.cc:174] Sets FaceBlendshapesGraph acceleration to xnnpack by default.\n",
      "I0000 00:00:1701875238.242719       1 gl_context.cc:344] GL version: 2.1 (2.1 ATI-4.12.7), renderer: AMD Radeon Pro 5300M OpenGL Engine\n",
      "W0000 00:00:1701875238.243221       1 face_landmarker_graph.cc:174] Sets FaceBlendshapesGraph acceleration to xnnpack by default.\n",
      "I0000 00:00:1701875238.442665       1 gl_context.cc:344] GL version: 2.1 (2.1 ATI-4.12.7), renderer: AMD Radeon Pro 5300M OpenGL Engine\n",
      "W0000 00:00:1701875238.443382       1 face_landmarker_graph.cc:174] Sets FaceBlendshapesGraph acceleration to xnnpack by default.\n",
      "I0000 00:00:1701875238.647187       1 gl_context.cc:344] GL version: 2.1 (2.1 ATI-4.12.7), renderer: AMD Radeon Pro 5300M OpenGL Engine\n",
      "W0000 00:00:1701875238.647868       1 face_landmarker_graph.cc:174] Sets FaceBlendshapesGraph acceleration to xnnpack by default.\n",
      "I0000 00:00:1701875238.978506       1 gl_context.cc:344] GL version: 2.1 (2.1 ATI-4.12.7), renderer: AMD Radeon Pro 5300M OpenGL Engine\n",
      "W0000 00:00:1701875238.979177       1 face_landmarker_graph.cc:174] Sets FaceBlendshapesGraph acceleration to xnnpack by default.\n",
      "I0000 00:00:1701875239.290401       1 gl_context.cc:344] GL version: 2.1 (2.1 ATI-4.12.7), renderer: AMD Radeon Pro 5300M OpenGL Engine\n",
      "W0000 00:00:1701875239.290997       1 face_landmarker_graph.cc:174] Sets FaceBlendshapesGraph acceleration to xnnpack by default.\n",
      "I0000 00:00:1701875239.621583       1 gl_context.cc:344] GL version: 2.1 (2.1 ATI-4.12.7), renderer: AMD Radeon Pro 5300M OpenGL Engine\n",
      "W0000 00:00:1701875239.622167       1 face_landmarker_graph.cc:174] Sets FaceBlendshapesGraph acceleration to xnnpack by default.\n",
      "I0000 00:00:1701875239.884894       1 gl_context.cc:344] GL version: 2.1 (2.1 ATI-4.12.7), renderer: AMD Radeon Pro 5300M OpenGL Engine\n",
      "W0000 00:00:1701875239.889798       1 face_landmarker_graph.cc:174] Sets FaceBlendshapesGraph acceleration to xnnpack by default.\n",
      "I0000 00:00:1701875240.144586       1 gl_context.cc:344] GL version: 2.1 (2.1 ATI-4.12.7), renderer: AMD Radeon Pro 5300M OpenGL Engine\n",
      "W0000 00:00:1701875240.145294       1 face_landmarker_graph.cc:174] Sets FaceBlendshapesGraph acceleration to xnnpack by default.\n",
      "I0000 00:00:1701875240.417185       1 gl_context.cc:344] GL version: 2.1 (2.1 ATI-4.12.7), renderer: AMD Radeon Pro 5300M OpenGL Engine\n",
      "W0000 00:00:1701875240.418148       1 face_landmarker_graph.cc:174] Sets FaceBlendshapesGraph acceleration to xnnpack by default.\n",
      "I0000 00:00:1701875240.745735       1 gl_context.cc:344] GL version: 2.1 (2.1 ATI-4.12.7), renderer: AMD Radeon Pro 5300M OpenGL Engine\n",
      "W0000 00:00:1701875240.746442       1 face_landmarker_graph.cc:174] Sets FaceBlendshapesGraph acceleration to xnnpack by default.\n",
      "I0000 00:00:1701875241.042401       1 gl_context.cc:344] GL version: 2.1 (2.1 ATI-4.12.7), renderer: AMD Radeon Pro 5300M OpenGL Engine\n",
      "W0000 00:00:1701875241.043193       1 face_landmarker_graph.cc:174] Sets FaceBlendshapesGraph acceleration to xnnpack by default.\n",
      "I0000 00:00:1701875241.346579       1 gl_context.cc:344] GL version: 2.1 (2.1 ATI-4.12.7), renderer: AMD Radeon Pro 5300M OpenGL Engine\n",
      "W0000 00:00:1701875241.347375       1 face_landmarker_graph.cc:174] Sets FaceBlendshapesGraph acceleration to xnnpack by default.\n",
      "I0000 00:00:1701875241.607914       1 gl_context.cc:344] GL version: 2.1 (2.1 ATI-4.12.7), renderer: AMD Radeon Pro 5300M OpenGL Engine\n",
      "W0000 00:00:1701875241.608450       1 face_landmarker_graph.cc:174] Sets FaceBlendshapesGraph acceleration to xnnpack by default.\n",
      "I0000 00:00:1701875241.841538       1 gl_context.cc:344] GL version: 2.1 (2.1 ATI-4.12.7), renderer: AMD Radeon Pro 5300M OpenGL Engine\n",
      "W0000 00:00:1701875241.842265       1 face_landmarker_graph.cc:174] Sets FaceBlendshapesGraph acceleration to xnnpack by default.\n",
      "I0000 00:00:1701875242.078822       1 gl_context.cc:344] GL version: 2.1 (2.1 ATI-4.12.7), renderer: AMD Radeon Pro 5300M OpenGL Engine\n",
      "W0000 00:00:1701875242.079574       1 face_landmarker_graph.cc:174] Sets FaceBlendshapesGraph acceleration to xnnpack by default.\n",
      "I0000 00:00:1701875242.346063       1 gl_context.cc:344] GL version: 2.1 (2.1 ATI-4.12.7), renderer: AMD Radeon Pro 5300M OpenGL Engine\n",
      "W0000 00:00:1701875242.346940       1 face_landmarker_graph.cc:174] Sets FaceBlendshapesGraph acceleration to xnnpack by default.\n",
      "I0000 00:00:1701875242.648775       1 gl_context.cc:344] GL version: 2.1 (2.1 ATI-4.12.7), renderer: AMD Radeon Pro 5300M OpenGL Engine\n",
      "W0000 00:00:1701875242.649506       1 face_landmarker_graph.cc:174] Sets FaceBlendshapesGraph acceleration to xnnpack by default.\n",
      "I0000 00:00:1701875242.942373       1 gl_context.cc:344] GL version: 2.1 (2.1 ATI-4.12.7), renderer: AMD Radeon Pro 5300M OpenGL Engine\n",
      "W0000 00:00:1701875242.943046       1 face_landmarker_graph.cc:174] Sets FaceBlendshapesGraph acceleration to xnnpack by default.\n",
      "I0000 00:00:1701875243.208587       1 gl_context.cc:344] GL version: 2.1 (2.1 ATI-4.12.7), renderer: AMD Radeon Pro 5300M OpenGL Engine\n",
      "W0000 00:00:1701875243.209267       1 face_landmarker_graph.cc:174] Sets FaceBlendshapesGraph acceleration to xnnpack by default.\n",
      "I0000 00:00:1701875243.477393       1 gl_context.cc:344] GL version: 2.1 (2.1 ATI-4.12.7), renderer: AMD Radeon Pro 5300M OpenGL Engine\n",
      "W0000 00:00:1701875243.478017       1 face_landmarker_graph.cc:174] Sets FaceBlendshapesGraph acceleration to xnnpack by default.\n",
      "I0000 00:00:1701875243.754938       1 gl_context.cc:344] GL version: 2.1 (2.1 ATI-4.12.7), renderer: AMD Radeon Pro 5300M OpenGL Engine\n",
      "W0000 00:00:1701875243.755661       1 face_landmarker_graph.cc:174] Sets FaceBlendshapesGraph acceleration to xnnpack by default.\n",
      "I0000 00:00:1701875244.048220       1 gl_context.cc:344] GL version: 2.1 (2.1 ATI-4.12.7), renderer: AMD Radeon Pro 5300M OpenGL Engine\n",
      "W0000 00:00:1701875244.048946       1 face_landmarker_graph.cc:174] Sets FaceBlendshapesGraph acceleration to xnnpack by default.\n",
      "I0000 00:00:1701875244.346028       1 gl_context.cc:344] GL version: 2.1 (2.1 ATI-4.12.7), renderer: AMD Radeon Pro 5300M OpenGL Engine\n",
      "W0000 00:00:1701875244.346472       1 face_landmarker_graph.cc:174] Sets FaceBlendshapesGraph acceleration to xnnpack by default.\n",
      "I0000 00:00:1701875244.505463       1 gl_context.cc:344] GL version: 2.1 (2.1 ATI-4.12.7), renderer: AMD Radeon Pro 5300M OpenGL Engine\n",
      "W0000 00:00:1701875244.505842       1 face_landmarker_graph.cc:174] Sets FaceBlendshapesGraph acceleration to xnnpack by default.\n",
      "I0000 00:00:1701875244.673495       1 gl_context.cc:344] GL version: 2.1 (2.1 ATI-4.12.7), renderer: AMD Radeon Pro 5300M OpenGL Engine\n",
      "W0000 00:00:1701875244.674229       1 face_landmarker_graph.cc:174] Sets FaceBlendshapesGraph acceleration to xnnpack by default.\n",
      "I0000 00:00:1701875244.841284       1 gl_context.cc:344] GL version: 2.1 (2.1 ATI-4.12.7), renderer: AMD Radeon Pro 5300M OpenGL Engine\n",
      "W0000 00:00:1701875244.841929       1 face_landmarker_graph.cc:174] Sets FaceBlendshapesGraph acceleration to xnnpack by default.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'verified': True, 'distance': 0.2865821987962347, 'threshold': 0.4, 'model': 'VGG-Face', 'detector_backend': 'opencv', 'similarity_metric': 'cosine', 'facial_areas': {'img1': {'x': 0, 'y': 0, 'w': 345, 'h': 234}, 'img2': {'x': 0, 'y': 0, 'w': 500, 'h': 543}}, 'time': 0.55}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1701875245.039399       1 gl_context.cc:344] GL version: 2.1 (2.1 ATI-4.12.7), renderer: AMD Radeon Pro 5300M OpenGL Engine\n",
      "W0000 00:00:1701875245.040009       1 face_landmarker_graph.cc:174] Sets FaceBlendshapesGraph acceleration to xnnpack by default.\n",
      "I0000 00:00:1701875245.243985       1 gl_context.cc:344] GL version: 2.1 (2.1 ATI-4.12.7), renderer: AMD Radeon Pro 5300M OpenGL Engine\n",
      "W0000 00:00:1701875245.244473       1 face_landmarker_graph.cc:174] Sets FaceBlendshapesGraph acceleration to xnnpack by default.\n",
      "I0000 00:00:1701875245.506424       1 gl_context.cc:344] GL version: 2.1 (2.1 ATI-4.12.7), renderer: AMD Radeon Pro 5300M OpenGL Engine\n",
      "W0000 00:00:1701875245.507059       1 face_landmarker_graph.cc:174] Sets FaceBlendshapesGraph acceleration to xnnpack by default.\n",
      "I0000 00:00:1701875245.813539       1 gl_context.cc:344] GL version: 2.1 (2.1 ATI-4.12.7), renderer: AMD Radeon Pro 5300M OpenGL Engine\n",
      "W0000 00:00:1701875245.814036       1 face_landmarker_graph.cc:174] Sets FaceBlendshapesGraph acceleration to xnnpack by default.\n",
      "I0000 00:00:1701875246.084766       1 gl_context.cc:344] GL version: 2.1 (2.1 ATI-4.12.7), renderer: AMD Radeon Pro 5300M OpenGL Engine\n",
      "W0000 00:00:1701875246.086755       1 face_landmarker_graph.cc:174] Sets FaceBlendshapesGraph acceleration to xnnpack by default.\n",
      "I0000 00:00:1701875246.955285       1 gl_context.cc:344] GL version: 2.1 (2.1 ATI-4.12.7), renderer: AMD Radeon Pro 5300M OpenGL Engine\n",
      "W0000 00:00:1701875246.956049       1 face_landmarker_graph.cc:174] Sets FaceBlendshapesGraph acceleration to xnnpack by default.\n",
      "I0000 00:00:1701875247.272693       1 gl_context.cc:344] GL version: 2.1 (2.1 ATI-4.12.7), renderer: AMD Radeon Pro 5300M OpenGL Engine\n",
      "W0000 00:00:1701875247.273438       1 face_landmarker_graph.cc:174] Sets FaceBlendshapesGraph acceleration to xnnpack by default.\n",
      "I0000 00:00:1701875247.540563       1 gl_context.cc:344] GL version: 2.1 (2.1 ATI-4.12.7), renderer: AMD Radeon Pro 5300M OpenGL Engine\n",
      "W0000 00:00:1701875247.541277       1 face_landmarker_graph.cc:174] Sets FaceBlendshapesGraph acceleration to xnnpack by default.\n",
      "I0000 00:00:1701875247.741110       1 gl_context.cc:344] GL version: 2.1 (2.1 ATI-4.12.7), renderer: AMD Radeon Pro 5300M OpenGL Engine\n",
      "W0000 00:00:1701875247.741705       1 face_landmarker_graph.cc:174] Sets FaceBlendshapesGraph acceleration to xnnpack by default.\n",
      "I0000 00:00:1701875247.939406       1 gl_context.cc:344] GL version: 2.1 (2.1 ATI-4.12.7), renderer: AMD Radeon Pro 5300M OpenGL Engine\n",
      "W0000 00:00:1701875247.940087       1 face_landmarker_graph.cc:174] Sets FaceBlendshapesGraph acceleration to xnnpack by default.\n",
      "I0000 00:00:1701875248.219969       1 gl_context.cc:344] GL version: 2.1 (2.1 ATI-4.12.7), renderer: AMD Radeon Pro 5300M OpenGL Engine\n",
      "W0000 00:00:1701875248.220712       1 face_landmarker_graph.cc:174] Sets FaceBlendshapesGraph acceleration to xnnpack by default.\n",
      "I0000 00:00:1701875248.478450       1 gl_context.cc:344] GL version: 2.1 (2.1 ATI-4.12.7), renderer: AMD Radeon Pro 5300M OpenGL Engine\n",
      "W0000 00:00:1701875248.479095       1 face_landmarker_graph.cc:174] Sets FaceBlendshapesGraph acceleration to xnnpack by default.\n",
      "I0000 00:00:1701875248.777779       1 gl_context.cc:344] GL version: 2.1 (2.1 ATI-4.12.7), renderer: AMD Radeon Pro 5300M OpenGL Engine\n",
      "W0000 00:00:1701875248.778402       1 face_landmarker_graph.cc:174] Sets FaceBlendshapesGraph acceleration to xnnpack by default.\n",
      "I0000 00:00:1701875249.011515       1 gl_context.cc:344] GL version: 2.1 (2.1 ATI-4.12.7), renderer: AMD Radeon Pro 5300M OpenGL Engine\n",
      "W0000 00:00:1701875249.012215       1 face_landmarker_graph.cc:174] Sets FaceBlendshapesGraph acceleration to xnnpack by default.\n",
      "I0000 00:00:1701875249.240222       1 gl_context.cc:344] GL version: 2.1 (2.1 ATI-4.12.7), renderer: AMD Radeon Pro 5300M OpenGL Engine\n",
      "W0000 00:00:1701875249.240884       1 face_landmarker_graph.cc:174] Sets FaceBlendshapesGraph acceleration to xnnpack by default.\n",
      "I0000 00:00:1701875249.509595       1 gl_context.cc:344] GL version: 2.1 (2.1 ATI-4.12.7), renderer: AMD Radeon Pro 5300M OpenGL Engine\n",
      "W0000 00:00:1701875249.510356       1 face_landmarker_graph.cc:174] Sets FaceBlendshapesGraph acceleration to xnnpack by default.\n",
      "I0000 00:00:1701875249.770577       1 gl_context.cc:344] GL version: 2.1 (2.1 ATI-4.12.7), renderer: AMD Radeon Pro 5300M OpenGL Engine\n",
      "W0000 00:00:1701875249.770994       1 face_landmarker_graph.cc:174] Sets FaceBlendshapesGraph acceleration to xnnpack by default.\n",
      "I0000 00:00:1701875249.937859       1 gl_context.cc:344] GL version: 2.1 (2.1 ATI-4.12.7), renderer: AMD Radeon Pro 5300M OpenGL Engine\n",
      "W0000 00:00:1701875249.938450       1 face_landmarker_graph.cc:174] Sets FaceBlendshapesGraph acceleration to xnnpack by default.\n",
      "I0000 00:00:1701875250.138837       1 gl_context.cc:344] GL version: 2.1 (2.1 ATI-4.12.7), renderer: AMD Radeon Pro 5300M OpenGL Engine\n",
      "W0000 00:00:1701875250.139564       1 face_landmarker_graph.cc:174] Sets FaceBlendshapesGraph acceleration to xnnpack by default.\n",
      "I0000 00:00:1701875250.405189       1 gl_context.cc:344] GL version: 2.1 (2.1 ATI-4.12.7), renderer: AMD Radeon Pro 5300M OpenGL Engine\n",
      "W0000 00:00:1701875250.405938       1 face_landmarker_graph.cc:174] Sets FaceBlendshapesGraph acceleration to xnnpack by default.\n",
      "I0000 00:00:1701875250.739830       1 gl_context.cc:344] GL version: 2.1 (2.1 ATI-4.12.7), renderer: AMD Radeon Pro 5300M OpenGL Engine\n",
      "W0000 00:00:1701875250.740389       1 face_landmarker_graph.cc:174] Sets FaceBlendshapesGraph acceleration to xnnpack by default.\n",
      "I0000 00:00:1701875251.049970       1 gl_context.cc:344] GL version: 2.1 (2.1 ATI-4.12.7), renderer: AMD Radeon Pro 5300M OpenGL Engine\n",
      "W0000 00:00:1701875251.050748       1 face_landmarker_graph.cc:174] Sets FaceBlendshapesGraph acceleration to xnnpack by default.\n",
      "I0000 00:00:1701875251.308541       1 gl_context.cc:344] GL version: 2.1 (2.1 ATI-4.12.7), renderer: AMD Radeon Pro 5300M OpenGL Engine\n",
      "W0000 00:00:1701875251.309219       1 face_landmarker_graph.cc:174] Sets FaceBlendshapesGraph acceleration to xnnpack by default.\n",
      "I0000 00:00:1701875251.609960       1 gl_context.cc:344] GL version: 2.1 (2.1 ATI-4.12.7), renderer: AMD Radeon Pro 5300M OpenGL Engine\n",
      "W0000 00:00:1701875251.610710       1 face_landmarker_graph.cc:174] Sets FaceBlendshapesGraph acceleration to xnnpack by default.\n",
      "I0000 00:00:1701875251.872188       1 gl_context.cc:344] GL version: 2.1 (2.1 ATI-4.12.7), renderer: AMD Radeon Pro 5300M OpenGL Engine\n",
      "W0000 00:00:1701875251.872906       1 face_landmarker_graph.cc:174] Sets FaceBlendshapesGraph acceleration to xnnpack by default.\n",
      "I0000 00:00:1701875252.138459       1 gl_context.cc:344] GL version: 2.1 (2.1 ATI-4.12.7), renderer: AMD Radeon Pro 5300M OpenGL Engine\n",
      "W0000 00:00:1701875252.139268       1 face_landmarker_graph.cc:174] Sets FaceBlendshapesGraph acceleration to xnnpack by default.\n",
      "I0000 00:00:1701875252.410531       1 gl_context.cc:344] GL version: 2.1 (2.1 ATI-4.12.7), renderer: AMD Radeon Pro 5300M OpenGL Engine\n",
      "W0000 00:00:1701875252.410965       1 face_landmarker_graph.cc:174] Sets FaceBlendshapesGraph acceleration to xnnpack by default.\n",
      "I0000 00:00:1701875252.571388       1 gl_context.cc:344] GL version: 2.1 (2.1 ATI-4.12.7), renderer: AMD Radeon Pro 5300M OpenGL Engine\n",
      "W0000 00:00:1701875252.571935       1 face_landmarker_graph.cc:174] Sets FaceBlendshapesGraph acceleration to xnnpack by default.\n",
      "I0000 00:00:1701875252.771165       1 gl_context.cc:344] GL version: 2.1 (2.1 ATI-4.12.7), renderer: AMD Radeon Pro 5300M OpenGL Engine\n",
      "W0000 00:00:1701875252.771830       1 face_landmarker_graph.cc:174] Sets FaceBlendshapesGraph acceleration to xnnpack by default.\n",
      "I0000 00:00:1701875253.107839       1 gl_context.cc:344] GL version: 2.1 (2.1 ATI-4.12.7), renderer: AMD Radeon Pro 5300M OpenGL Engine\n",
      "W0000 00:00:1701875253.108444       1 face_landmarker_graph.cc:174] Sets FaceBlendshapesGraph acceleration to xnnpack by default.\n",
      "I0000 00:00:1701875253.379682       1 gl_context.cc:344] GL version: 2.1 (2.1 ATI-4.12.7), renderer: AMD Radeon Pro 5300M OpenGL Engine\n",
      "W0000 00:00:1701875253.380422       1 face_landmarker_graph.cc:174] Sets FaceBlendshapesGraph acceleration to xnnpack by default.\n",
      "I0000 00:00:1701875253.639204       1 gl_context.cc:344] GL version: 2.1 (2.1 ATI-4.12.7), renderer: AMD Radeon Pro 5300M OpenGL Engine\n",
      "W0000 00:00:1701875253.639979       1 face_landmarker_graph.cc:174] Sets FaceBlendshapesGraph acceleration to xnnpack by default.\n",
      "I0000 00:00:1701875253.904451       1 gl_context.cc:344] GL version: 2.1 (2.1 ATI-4.12.7), renderer: AMD Radeon Pro 5300M OpenGL Engine\n",
      "W0000 00:00:1701875253.905306       1 face_landmarker_graph.cc:174] Sets FaceBlendshapesGraph acceleration to xnnpack by default.\n",
      "I0000 00:00:1701875254.172644       1 gl_context.cc:344] GL version: 2.1 (2.1 ATI-4.12.7), renderer: AMD Radeon Pro 5300M OpenGL Engine\n",
      "W0000 00:00:1701875254.173370       1 face_landmarker_graph.cc:174] Sets FaceBlendshapesGraph acceleration to xnnpack by default.\n",
      "I0000 00:00:1701875254.436072       1 gl_context.cc:344] GL version: 2.1 (2.1 ATI-4.12.7), renderer: AMD Radeon Pro 5300M OpenGL Engine\n",
      "W0000 00:00:1701875254.436754       1 face_landmarker_graph.cc:174] Sets FaceBlendshapesGraph acceleration to xnnpack by default.\n",
      "I0000 00:00:1701875254.710242       1 gl_context.cc:344] GL version: 2.1 (2.1 ATI-4.12.7), renderer: AMD Radeon Pro 5300M OpenGL Engine\n",
      "W0000 00:00:1701875254.711519       1 face_landmarker_graph.cc:174] Sets FaceBlendshapesGraph acceleration to xnnpack by default.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/josepenaseco/Desktop/dev/vc/p6/p6_vc.ipynb Celda 32\u001b[0m line \u001b[0;36m3\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/josepenaseco/Desktop/dev/vc/p6/p6_vc.ipynb#Y245sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m state_machine \u001b[39m=\u001b[39m StateMachine\u001b[39m.\u001b[39mstart_building()\u001b[39m.\u001b[39madd_state(\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/josepenaseco/Desktop/dev/vc/p6/p6_vc.ipynb#Y245sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m         State\u001b[39m.\u001b[39mdefault(\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/josepenaseco/Desktop/dev/vc/p6/p6_vc.ipynb#Y245sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m             name\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mLOCK\u001b[39m\u001b[39m\"\u001b[39m, \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/josepenaseco/Desktop/dev/vc/p6/p6_vc.ipynb#Y245sZmlsZQ%3D%3D?line=28'>29</a>\u001b[0m             \u001b[39m.\u001b[39mdo(Transition\u001b[39m.\u001b[39mto(\u001b[39m\"\u001b[39m\u001b[39mLOCK\u001b[39m\u001b[39m\"\u001b[39m)\u001b[39m.\u001b[39mwhen(InputManager\u001b[39m.\u001b[39mis_space_pressed))\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/josepenaseco/Desktop/dev/vc/p6/p6_vc.ipynb#Y245sZmlsZQ%3D%3D?line=29'>30</a>\u001b[0m     )\u001b[39m.\u001b[39mbuild()\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/josepenaseco/Desktop/dev/vc/p6/p6_vc.ipynb#Y245sZmlsZQ%3D%3D?line=31'>32</a>\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/josepenaseco/Desktop/dev/vc/p6/p6_vc.ipynb#Y245sZmlsZQ%3D%3D?line=32'>33</a>\u001b[0m     ret, frame \u001b[39m=\u001b[39m video\u001b[39m.\u001b[39;49mread()\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/josepenaseco/Desktop/dev/vc/p6/p6_vc.ipynb#Y245sZmlsZQ%3D%3D?line=33'>34</a>\u001b[0m     state_machine\u001b[39m.\u001b[39mexecute(frame)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/josepenaseco/Desktop/dev/vc/p6/p6_vc.ipynb#Y245sZmlsZQ%3D%3D?line=34'>35</a>\u001b[0m     cv\u001b[39m.\u001b[39mimshow(\u001b[39m'\u001b[39m\u001b[39mVideo\u001b[39m\u001b[39m'\u001b[39m, frame)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import cv2 as cv\n",
    "\n",
    "\n",
    "video = cv.VideoCapture(0)\n",
    "authorizator = FaceAuthorizator(face_detector=RetinafaceFaceDetector(),face_comparator=DeepfaceFaceComparator(), base_path='./faces/comparator/sara/', threshold=0.5)\n",
    "\n",
    "state_machine = StateMachine.start_building().add_state(\n",
    "        State.default(\n",
    "            name=\"LOCK\", \n",
    "            screen=LockAuthenticationScreen)\n",
    "                    .do(Transition.to(\"RECOGNIZING\").when(InputManager.is_space_pressed))\n",
    "    ).add_state(\n",
    "        State.of( \n",
    "            name=\"RECOGNIZING\", \n",
    "            screen=FaceRecognizerAuthenticationScreen)\n",
    "                .do(Transition.to(\"GRANTED\").when(authorizator.is_access_granted))\n",
    "                .do(Transition.to(\"DENIED\").when(authorizator.is_access_denied))\n",
    "                .do_on_enter(authorizator.start_authorization_thread)\n",
    "    ).add_state(\n",
    "        State.of(\n",
    "            name=\"GRANTED\", \n",
    "            screen =AccessGrantedAuthenticationScreen)\n",
    "                    .do(Transition.to(\"LOCK\").when(InputManager.is_space_pressed))\n",
    "    ).add_state(\n",
    "\n",
    "    State.of(\n",
    "          name=\"DENIED\", \n",
    "          screen=AccessDeniedAuthenticationScreen)\n",
    "            .do(Transition.to(\"LOCK\").when(InputManager.is_space_pressed))\n",
    "    ).build()\n",
    "\n",
    "while True:\n",
    "    ret, frame = video.read()\n",
    "    state_machine.execute(frame)\n",
    "    cv.imshow('Video', frame)\n",
    "\n",
    "    if cv.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "video.release()\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ WARN:0@6166.814] global loadsave.cpp:248 findDecoder imread_('./faces/comparator/5.jpeg'): can't open/read file: check file path/integrity\n",
      "I0000 00:00:1701875187.395875       1 gl_context.cc:344] GL version: 2.1 (2.1 ATI-4.12.7), renderer: AMD Radeon Pro 5300M OpenGL Engine\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "__init__(): incompatible constructor arguments. The following argument types are supported:\n    1. mediapipe.python._framework_bindings.image.Image(image_format: mediapipe::ImageFormat_Format, data: numpy.ndarray[numpy.uint8])\n    2. mediapipe.python._framework_bindings.image.Image(image_format: mediapipe::ImageFormat_Format, data: numpy.ndarray[numpy.uint16])\n    3. mediapipe.python._framework_bindings.image.Image(image_format: mediapipe::ImageFormat_Format, data: numpy.ndarray[numpy.float32])\n\nInvoked with: kwargs: image_format=<ImageFormat.SRGB: 1>, data=None",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/Users/josepenaseco/Desktop/dev/vc/p6/p6_vc.ipynb Celda 33\u001b[0m line \u001b[0;36m7\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/josepenaseco/Desktop/dev/vc/p6/p6_vc.ipynb#Y246sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m detector \u001b[39m=\u001b[39m MediaPipeFaceDetector()\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/josepenaseco/Desktop/dev/vc/p6/p6_vc.ipynb#Y246sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m img \u001b[39m=\u001b[39m cv\u001b[39m.\u001b[39mimread(\u001b[39m\"\u001b[39m\u001b[39m./faces/comparator/5.jpeg\u001b[39m\u001b[39m\"\u001b[39m) \n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/josepenaseco/Desktop/dev/vc/p6/p6_vc.ipynb#Y246sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m face_comparer \u001b[39m=\u001b[39m face_detector\u001b[39m.\u001b[39;49mdetect(img)[\u001b[39m0\u001b[39m]\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/josepenaseco/Desktop/dev/vc/p6/p6_vc.ipynb#Y246sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m video \u001b[39m=\u001b[39m cv\u001b[39m.\u001b[39mVideoCapture(\u001b[39m0\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/josepenaseco/Desktop/dev/vc/p6/p6_vc.ipynb#Y246sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n",
      "\u001b[1;32m/Users/josepenaseco/Desktop/dev/vc/p6/p6_vc.ipynb Celda 33\u001b[0m line \u001b[0;36m4\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/josepenaseco/Desktop/dev/vc/p6/p6_vc.ipynb#Y246sZmlsZQ%3D%3D?line=39'>40</a>\u001b[0m options \u001b[39m=\u001b[39m FaceDetectorOptions(\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/josepenaseco/Desktop/dev/vc/p6/p6_vc.ipynb#Y246sZmlsZQ%3D%3D?line=40'>41</a>\u001b[0m     base_options\u001b[39m=\u001b[39mBaseOptions(model_asset_path\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39m./blaze_face_short_range.tflite\u001b[39m\u001b[39m'\u001b[39m),\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/josepenaseco/Desktop/dev/vc/p6/p6_vc.ipynb#Y246sZmlsZQ%3D%3D?line=41'>42</a>\u001b[0m     running_mode\u001b[39m=\u001b[39mVisionRunningMode\u001b[39m.\u001b[39mIMAGE)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/josepenaseco/Desktop/dev/vc/p6/p6_vc.ipynb#Y246sZmlsZQ%3D%3D?line=43'>44</a>\u001b[0m \u001b[39mwith\u001b[39;00m FaceDetector\u001b[39m.\u001b[39mcreate_from_options(options) \u001b[39mas\u001b[39;00m detector:\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/josepenaseco/Desktop/dev/vc/p6/p6_vc.ipynb#Y246sZmlsZQ%3D%3D?line=44'>45</a>\u001b[0m     mp_image \u001b[39m=\u001b[39m mp\u001b[39m.\u001b[39;49mImage(image_format\u001b[39m=\u001b[39;49mmp\u001b[39m.\u001b[39;49mImageFormat\u001b[39m.\u001b[39;49mSRGB, data\u001b[39m=\u001b[39;49mimage)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/josepenaseco/Desktop/dev/vc/p6/p6_vc.ipynb#Y246sZmlsZQ%3D%3D?line=45'>46</a>\u001b[0m     face_detector_result \u001b[39m=\u001b[39m detector\u001b[39m.\u001b[39mdetect(mp_image)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/josepenaseco/Desktop/dev/vc/p6/p6_vc.ipynb#Y246sZmlsZQ%3D%3D?line=46'>47</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_convert_to_face_detector_result(image, [(x\u001b[39m.\u001b[39mbounding_box\u001b[39m.\u001b[39morigin_x, x\u001b[39m.\u001b[39mbounding_box\u001b[39m.\u001b[39morigin_y, x\u001b[39m.\u001b[39mbounding_box\u001b[39m.\u001b[39mwidth, x\u001b[39m.\u001b[39mbounding_box\u001b[39m.\u001b[39mheight) \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m face_detector_result\u001b[39m.\u001b[39mdetections])\n",
      "\u001b[0;31mTypeError\u001b[0m: __init__(): incompatible constructor arguments. The following argument types are supported:\n    1. mediapipe.python._framework_bindings.image.Image(image_format: mediapipe::ImageFormat_Format, data: numpy.ndarray[numpy.uint8])\n    2. mediapipe.python._framework_bindings.image.Image(image_format: mediapipe::ImageFormat_Format, data: numpy.ndarray[numpy.uint16])\n    3. mediapipe.python._framework_bindings.image.Image(image_format: mediapipe::ImageFormat_Format, data: numpy.ndarray[numpy.float32])\n\nInvoked with: kwargs: image_format=<ImageFormat.SRGB: 1>, data=None"
     ]
    }
   ],
   "source": [
    "import cv2 as cv\n",
    "\n",
    "comparator = DeepfaceFaceComparator()\n",
    "detector = MediaPipeFaceDetector()\n",
    "\n",
    "img = cv.imread(\"./faces/comparator/5.jpeg\") \n",
    "face_comparer = face_detector.detect(img)[0]\n",
    "\n",
    "video = cv.VideoCapture(0)\n",
    "\n",
    "while True:\n",
    "    ret, frame = video.read()\n",
    "    faces = face_detector.detect(frame)\n",
    "\n",
    "    for face in faces:\n",
    "        result = comparator.qualify(face, face_comparer)\n",
    "        print(result.similarity)\n",
    "\n",
    "    cv.imshow('Video', frame)\n",
    "    \n",
    "    if cv.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "video.release()\n",
    "cv.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
